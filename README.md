# Attention Mechanisms in Medical Image Segmentation: A Survey

> **A Comprehensive Survey on Medical image segmentation.** . [[paper](https://arxiv.org/abs/2305.17937)] [[homepage](https://github.com/Ammexm/Medical-Image-Segmentation)]

> **<p align="justify"> Abstract:** *......* </p>


> **Medical Image Segmentation Models:** A curated list of Medical Image Segmentation models in computer vision and beyond. This repository supplements our survey paper. We intend to continuously update it.
#### If you like our project, please give us a star ‚≠ê on GitHub for latest update.
____

## üòÆ Highlights
```
- 2024.05.27: Latest update of this paper list.
- 2023.05.29: The paper was online.
```
## Contents
- [List of related papers and code](#List-of-related-papers-and-code) 
  - [Pre-Transformer Attention in Medical Segmentation](#Pre-Transformer-Attention-in-Medical-Segmentation)
  - [Transformer in medical Segmentation](#Transformer-in-medical-Segmentation)
  - [Mamba in medical Segmentation](#Mamba-in-medical-Segmentation)
## Citation

If you find our work useful in your research, please consider citing:
```

```

## List of related papers and code
### Pre-Transformer Attention in Medical Segmentation
- **Cell-DETR:** Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz.<br />
  "Attention-based transformers for instance segmentation of cells in microstructures" **IEEE BIBM (2020)**.
  [[paper](https://arxiv.org/pdf/2102.11650)]
  [[code](https://git.rwth-aachen.de/bcs/projects/cell-detr.git)]
  



### Transformer in medical Segmentation
- **Cell-DETR:** Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz.<br />
  "Attention-based transformers for instance segmentation of cells in microstructures" **IEEE BIBM (2020)**.
  [[paper](https://arxiv.org/pdf/2102.11650)]
  [[code](https://git.rwth-aachen.de/bcs/projects/cell-detr.git)]
  
- **TransUNet:** Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L and Zhou, Yuyin.<br />
  "TransUNet:¬†Transformers¬†Make Strong Encoders for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2102.04306)]
  [[code](https://github.com/Beckschen/TransUNet)]

- Karimi, Davood and Vasylechko, Serge Didenko and Gholipour, Ali.<br />
  "Convolution-free medical image segmentation using transformers" **MICCAI  (2021)**.
  [[paper](https://arxiv.org/abs/2102.13645)]
  [[code](https://github.com/Beckschen/TransUNet)]

- **CoTr:** Xie, Yutong and Zhang, Jianpeng and Shen, Chunhua and Xia, Yong.<br />
  "CoTr: Efficiently Bridging CNN and Transformer for 3D Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2103.03024)]
  [[code](https://github.com/YtongXie/CoTr)]

- **SpecTr:** Yun, Boxiang and Wang, Yan and Chen, Jieneng and Wang, Huiyu and Shen, Wei and Li, Qingli.<br />
  "SpecTr: Spectral¬†Transformer¬†for Hyperspectral Pathology Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2103.03604)]
  [[code](https://github.com/hfut-xc-yun/SpecTr)]

- **Medical¬†Transformer:** Jun, Eunji and Jeong, Seungwoo and Heo, Da-Woon and Suk, Heung-Il.<br />
  "Medical¬†Transformer: Universal Brain Encoder for 3D MRI Analysis" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2104.13633)]
  [[code](https://github.com/hfut-xc-yun/SpecTr)]

- **Swin-Unet:** Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning.<br />
  "Swin-Unet: Unet-like Pure¬†Transformer¬†for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2105.05537)]
  [[code](https://github.com/HuCaoFighting/Swin-Unet)]

- **Segtran:** Li, Shaohua and Sui, Xiuchao and Luo, Xiangde and Xu, Xinxing and Liu, Yong and Goh, Rick.<br />
  "Medical Image Segmentation Using Squeeze-and-Expansion¬†Transformers" **IJCAI (2021)**.
  [[paper](https://arxiv.org/abs/2105.09511)]
  [[code](https://github.com/askerlee/segtran)]

- **TransBTS:** Wenxuan, Wang and Chen, Chen and Meng, Ding and Hong, Yu and Sen, Zha and Jiangyun, Li.<br />
  "TransBTS: Multimodal Brain Tumor Segmentation Using¬†Transformer" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2103.04430)]
  [[code](https://github.com/Wenxuan-1119/TransBTS)]

- **MCTrans:** Ji, Yuanfeng and Zhang, Ruimao and Wang, Huijie and Li, Zhen and Wu, Lingyun and Zhang, Shaoting and Luo, Ping.<br />
  "Multi-Compound¬†Transformer¬†for Accurate Biomedical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2106.14385)]
  [[code](https://github.com/JiYuanFeng/MCTrans)

- **MedT:** Valanarasu, Jeya Maria Jose and Oza, Poojan and Hacihaliloglu, Ilker and Patel, Vishal M.<br />
  "Medical¬†Transformer: Gated Axial-Attention for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2102.10662)]
  [[code](https://github.com/jeya-maria-jose/Medical-Transformer)]

- **TransFuse:** Zhang, Yundong and Liu, Huiye and Hu, Qiang.<br />
  "TransFuse: Fusing¬†Transformers¬†and CNNs for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2102.08005)]

- **TransClaw U-Net:** Yao, Chang and Hu, Menghan and Li, Qingli and Zhai, Guangtao and Zhang, Xiao-Ping.<br />
  "TransClaw U-Net: Claw U-Net with¬†Transformers¬†for Medical Image Segmentation" **ICICSP (2022)**.
  [[paper](https://arxiv.org/abs/2107.05188)]

- **TransAttUnet:** Chen, Bingzhi and Liu, Yishu and Zhang, Zheng and Lu, Guangming and Kong, Adams Wai Kin.<br />
  "TransAttUnet: Multi-level Attention-guided U-Net with¬†Transformer¬†for Medical Image Segmentation" **TETCI (2023)**.
  [[paper](https://arxiv.org/abs/2107.05274)]
  [[code](https://github.com/YishuLiu/TransAttUnet)]

- **LeViT-UNet:** Xu, Guoping and Zhang, Xuan and He, Xinwei and Wu, Xinglong.<br />
  "LeViT-UNet: Make Faster Encoders with¬†Transformer¬†for Medical Image Segmentation" **PRCV (2023)**.
  [[paper](https://arxiv.org/abs/2107.08623)]
  [[code](https://github.com/apple1986/LeViT_UNet)]

- **Polyp-PVT:** Dong, Bo and Wang, Wenhai and Fan, Deng-Ping and Li, Jinpeng and Fu, Huazhu and Shao, Ling.<br />
  "Polyp-PVT: Polyp Segmentation with Pyramid Vision¬†Transformers" **CAAI AIR (2023)**.
  [[paper](https://arxiv.org/abs/2108.06932)]
  [[code](https://github.com/DengPingFan/Polyp-PVT)]

- **PMTrans:** Zhang, Zhuangzhuang and Zhang, Weixiong.<br />
  "Pyramid Medical¬†Transformer¬†for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2104.14702)]

- **MISSFormer:** Huang, Xiaohong and Deng, Zhifang and Li, Dandan and Yuan, Xueguang.<br />
  "MISSFormer: An Effective Medical Image Segmentation¬†Transformer" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.07162)]
  [[code](https://github.com/ZhifangDeng/MISSFormer)]

- **TUnet:** Sha, Youyang and Zhang, Yonghong and Ji, Xuquan and Hu, Lei.<br />
  "Transformer-Unet: Raw Image Processing with Unet" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.08417)]

- **BiTr-Unet:** Jia, Qiran and Shu, Hai.<br />
  "BiTr-Unet: a CNN-Transformer¬†Combined Network for MRI Brain Tumor Segmentation" **International MICCAI Brainlesion Workshop (2021)**.
  [[paper](https://arxiv.org/abs/2109.12271)]
  [[code](https://github.com/JustaTinyDot/BiTr-Unet)]

- **UTNet:** Gao, Yunhe and Zhou, Mu and Metaxas, Dimitris N.<br />
  "UTNet: A Hybrid¬†Transformer¬†Architecture for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2107.00781)]
  [[code](https://github.com/yhygao/UTNet)]

- **GT U-Net:** Li, Yunxiang and Wang, Shuai and Wang, Jun and Zeng, Guodong and Liu, Wenjun and Zhang, Qianni and Jin, Qun and Wang, Yaqi.<br />
  "GT U-Net: A U-Net Like Group¬†Transformer¬†Network for Tooth Root Segmentation" **International Workshop on MIMI (2021)**.
  [[paper](https://arxiv.org/abs/2109.14813)]
  [[code](https://github.com/Kent0n-Li/GT-U-Net)]

- **nnFormer:** Zhou, Hong-Yu and Guo, Jiansen and Zhang, Yinghao and Yu, Lequan and Wang, Liansheng and Yu, Yizhou.<br />
  "nnFormer: Interleaved¬†Transformer¬†for Volumetric Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.03201)]
  [[code](https://git.io/JSf3i)]

- Pandey, Deepanshu and Gupta, Pradyumna and Bhattacharya, Sumit and Sinha, Aman and Agarwal, Rohit.<br />
  "Transformer¬†Assisted Convolutional Network for Cell Instance Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.02270)]
  [[code](https://github.com/dsciitism/SegPC-2021)]

- **BAT:** Wang, Jiacheng and Wei, Lan and Wang, Liansheng and Zhou, Qichao and Zhu, Lei and Qin, Jing.<br />
  "Boundary-aware¬†Transformers¬†for Skin Lesion Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2110.03864)]
  [[code](https://github.com/jcwang123/BA-Transformer)]

- **UNETR:** Hatamizadeh, Ali and Tang, Yucheng and Nath, Vishwesh and Yang, Dong and Myronenko, Andriy and Landman, Bennett and Roth, Holger R and Xu, Daguang.<br />
  "UNETR:¬†Transformers¬†for 3D Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://arxiv.org/abs/2103.10504)]
  [[code](https://monai.io/research/unetr)]

- Dobko, Mariia and Kolinko, Danylo-Ivan and Viniavskyi, Ostap and Yelisieiev, Yurii.<br />
  "Combining CNNs With¬†Transformer¬†for Multimodal 3D MRI Brain Tumor Segmentation With Self-Supervised Pretraining" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.07919)]
  [[code](https://github.com/ucuapps/BraTS2021_Challenge)]

- **Bilateral-ViT:** Song, Sifan and Dang, Kang and Yu, Qinji and Wang, Zilong and Coenen, Frans and Su, Jionglong and Ding, Xiaowei.<br />
  "Bilateral-ViT for Robust Fovea Localization" **ISBI (2022)**.
  [[paper](https://arxiv.org/abs/2110.09860)]

- **BiTrans:** Wei, Jianze and Huang, Huaibo and Sun, Muyi and Wang, Yunlong and Ren, Min and He, Ran and Sun, Zhenan.<br />
  "Toward Accurate and Reliable Iris Segmentation Using Uncertainty Learning" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.10334)]

- **AFTer-UNet:** Yan, Xiangyi and Tang, Hao and Sun, Shanlin and Ma, Haoyu and Kong, Deying and Xie, Xiaohui.<br />
  "AFTer-UNet: Axial Fusion¬†Transformer¬†UNet for Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://arxiv.org/abs/2110.10403)]

- **DTNet:** Li, Yunxiang and Li, Jingxiong and Dan, Ruilong and Wang, Shuai and Jin, Kai and Zeng, Guodong and Wang, Jun and Pan, Xiangji and Zhang, Qianni and Zhou, Huiyu and others.<br />
  "Dispensed¬†Transformer¬†Network for Unsupervised Domain Adaptation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.14944)]
  [[code](https://github.com/Kent0n-Li/DTNet)]

- **MT-UNet:** Wang, Hongyi and Xie, Shiao and Lin, Lanfen and Iwamoto, Yutaro and Han, Xian-Hua and Chen, Yen-Wei and Tong, Ruofeng.<br />
  "Mixed¬†Transformer¬†U-Net For Medical Image Segmentation" **ICASSP (2022)**.
  [[paper](https://arxiv.org/abs/2111.04734)]
  [[code](https://github.com/Dootmaan/MT-UNet)]

- **VT-UNet:** Peiris, H and Hayat, M and Chen, Z and Egan, G and Harandi, M.<br />
  "A Volumetric¬†Transformer¬†for Accurate 3D Tumor Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2111.13300)]
  [[code](https://github.com/himashi92/VT-UNet)]

- Tang, Yucheng and Yang, Dong and Li, Wenqi and Roth, Holger R and Landman, Bennett and Xu, Daguang and Nath, Vishwesh and Hatamizadeh, Ali.<br />
  "Self-Supervised Pre-Training of Swin¬†Transformers¬†for 3D Medical Image Analysis" **CVPR (2022)**.
  [[paper](https://arxiv.org/abs/2111.14791)]
  [[code](https://monai.io/research/swin-unetr)]

- **UCTransNet:** Wang, Haonan and Cao, Peng and Wang, Jiaqi and Zaiane, Osmar R.<br />
  "UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer" **AAAI (2022)**.
  [[paper](https://arxiv.org/abs/2109.04335)]
  [[code](https://github.com/McGregorWwww/UCTransNet)]

- **Swin UNETR:** Hatamizadeh, Ali and Nath, Vishwesh and Tang, Yucheng and Yang, Dong and Roth, Holger R and Xu, Daguang.<br />
  "Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images" **International MICCAI Brainlesion Workshop (2021)**.
  [[paper](https://arxiv.org/abs/2201.01266)]
  [[code](https://monai.io/research/swin-unetr)]

- **ViTBIS:** Sagar, Abhinav.<br />
  "ViTBIS: Vision Transformer for Biomedical Image Segmentation" **MICCAI Workshop on Distributed and Collaborative Learning (2021)**.
  [[paper](https://arxiv.org/abs/2201.05920)]

- **TransBTSV2:** Li, Jiangyun and Wang, Wenxuan and Chen, Chen and Zhang, Tianxiang and Zha, Sen and Yu, Hong and Wang, Jing.<br />
  "TransBTSV2: Wider Instead of Deeper Transformer for Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2201.12785)]
  [[code](https://github.com/Wenxuan-1119/TransBTS)]

- **SSFormer:** Wang, Jinfeng and Huang, Qiming and Tang, Feilong and Meng, Jia and Su, Jionglong and Song, Sifan.<br />
  "Stepwise Feature Fusion: Local Guides Global" **MICCAI (2022)**.
  [[paper](https://arxiv.org/abs/2203.03635)]
  [[code](https://github.com/Qiming-Huang/ssformer)]

- **SwinBTS:** Jiang, Yun and Zhang, Yuan and Lin, Xin and Dong, Jinkun and Cheng, Tongtong and Liang, Jing.<br />
  "SwinBTS: A method for 3D multimodal brain tumor¬†segmentation¬†using swin¬†transformer" **Brain sciences (2022)**.
  [[paper](https://www.mdpi.com/2076-3425/12/6/797/pdf)]
  [[code](https://github.com/langwangdezhexue/Swin_BTS)]

- **3D PSwinBTS:** Liang, Junjie and Yang, Cihui and Zeng, Lingguo.<br />
  "3D PSwinBTS: An efficient¬†transformer-based Unet using 3D parallel shifted windows for brain tumor¬†segmentation" **Digital Signal Processing (2022)**.

- **TranSiam:** Li, Xuejian and Ma, Shiqiang and Tang, Jijun and Guo, Fei.<br />
  "TranSiam: Fusing Multimodal Visual Features Using¬†Transformer¬†for¬†Medical¬†Image¬†Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2204.12185)]

- **BTSwin-Unet:** Liang, Junjie and Yang, Cihui and Zhong, Jingting and Ye, Xiaoli.<br />
  "BTSwin-Unet: 3D U-shaped Symmetrical Swin¬†Transformer-based Network for Brain Tumor¬†Segmentation¬†with Self-supervised Pre-trainin" **Neural processing letters (2023)**.



### Mamba in medical Segmentation
- **Mamba:** Gu, Albert and Dao, Tri.<br />
  "Mamba: Linear-Time Sequence Modeling with Selective State Spaces" **arXiv (2023)**.
  [[paper](https://arxiv.org/abs/2312.00752)] 

- **Vim:** Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang.<br />
  "Vision mamba: Efficient visual representation learning with bidirectional state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.09417)] 

- **Vmamba:** Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan.<br />
  "Vmamba: Visual state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.10166)]
  [[code](https://github.com/MzeroMiko/VMamba)]

- **Segmamba:** Xing, Zhaohu and Ye, Tian and Yang, Yijun and Liu, Guang and Zhu, Lei.<br />
  "Segmamba: Long-range sequential modeling mamba for 3d medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.13560)]
  [[code]()]

- **U-mamba:** Ma, Jun and Li, Feifei and Wang, Bo.<br />
  "U-mamba: Enhancing long-range dependency for biomedical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.04722)]
  [[code](https://wanglab.ai/u-mamba.html)]

- **H-vmunet:** Wu, Renkai and Liu, Yinghao and Liang, Pengchen and Chang, Qing.<br />
  "H-vmunet: High-order vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.13642)]
  [[code](https://github.com/wurenkai/H-vmunet)]

- **LightM-UNet:** Liao, Weibin and Zhu, Yinghao and Wang, Xinyuan and Pan, Cehngwei and Wang, Yasha and Ma, Liantao.<br />
  "Lightm-unet: Mamba assists in lightweight unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.05246)]
  [[code](https://github.com/MrBlankness/LightM-UNet)]

- **Swin-UMamba:** Liu, Jiarun and Yang, Hao and Zhou, Hong-Yu and Xi, Yan and Yu, Lequan and Yu, Yizhou and Liang, Yong and Shi, Guangming and Zhang, Shaoting and Zheng, Hairong and others.<br />
  "Swin-umamba: Mamba-based unet with imagenet-based pretraining" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.03302)]
  [[code](https://github.com/JiarunLiu/Swin-UMamba)]

- **VM-UNet:** Ruan, Jiacheng and Xiang, Suncheng.<br />
  "Vm-unet: Vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.02491)]
  [[code](https://github.com/JCruan519/VM-UNet)]

- **VM-UNET-V2:** Zhang, Mingya and Yu, Yue and Gu, Limei and Lin, Tingsheng and Tao, Xianping.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.09157)]
  [[code](https://github.com/nobodyplayer1/VM-UNetV2)]

- **LMa-UNet:** Wang, Jinhong and Chen, Jintai and Chen, Danny and Wu, Jian.<br />
  "Large window-based mamba unet for medical image segmentation: Beyond convolution and self-attention" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.07332)]
  [[code](https://github.com/wjh892521292/LMa-UNet)]

- **Mamba-UNet:** Wang, Ziyang and Zheng, Jian-Qing and Zhang, Yichi and Cui, Ge and Li, Lei.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.05079)]
  [[code](https://github.com/ziyangwang007/Mamba-UNet)]

- **TM-UNet:** Tang, Hao and Cheng, Lianglun and Huang, Guoheng and Tan, Zhengguang and Lu, Junhao and Wu, Kaihong.<br />
  "Rotate to scan: Unet-like mamba with triplet ssm module for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.17701)]

- **P-Mamba:** Ye, Zi and Chen, Tianxiang.<br />
  "P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.08506)]
