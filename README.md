# Attention Mechanisms in Medical Image Segmentation: A Survey

> **A Comprehensive Survey on Segment Anything Model for Vision and Beyond.** . [[paper](https://arxiv.org/abs/2305.17937)] [[homepage](https://github.com/Ammexm/Medical-Image-Segmentation)]

> **<p align="justify"> Abstract:** *......* </p>


> **Medical Image Segmentation Models:** A curated list of Medical Image Segmentation models in computer vision and beyond. This repository supplements our survey paper. We intend to continuously update it.
#### If you like our project, please give us a star ‚≠ê on GitHub for latest update.
____

## üòÆ Highlights
```
- 2024.05.22: Latest update of this paper list.
- 2023.05.29: The paper was online.
```
## Contents
- [List of related papers and code](#List-of-related-papers-and-code) 
  - [Pre-Transformer Attention in Medical Segmentation](#Pre-Transformer-Attention-in-Medical-Segmentatio)
  - [Transformer in medical Segmentation](#Transformer-in-medical-Segmentation)
  - [Mamba in medical Segmentation](#Mamba-in-medical-Segmentation)
## Citation

If you find our work useful in your research, please consider citing:
```

```

## List of related papers and code
### Pre-Transformer Attention in Medical Segmentation
- **TransUnet:** Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L., and Zhou, Yuyin.<br />
  "Transunet: Transformers make strong encoders for medical image segmentation" **ICCV (2023) Best Paper Honorable Mention**.
  [[paper](https://arxiv.org/pdf/2102.04306)] 
  [[code](https://github.com/Beckschen/TransUNet)]

### Transformer in medical Segmentation
- **TransUnet:** Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L., and Zhou, Yuyin.<br />
  "Transunet: Transformers make strong encoders for medical image segmentation" **ICCV (2023) Best Paper Honorable Mention**.
  [[paper](https://arxiv.org/pdf/2102.04306)] 
  [[code](https://github.com/Beckschen/TransUNet)]

### Mamba in medical Segmentation
- **Mamba:** Gu, Albert and Dao, Tri.<br />
  "Mamba: Linear-Time Sequence Modeling with Selective State Spaces" **arXiv (2023)**.
  [[paper](https://arxiv.org/abs/2312.00752)] 

- **Vim:** Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang.<br />
  "Vision mamba: Efficient visual representation learning with bidirectional state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.09417)] 

- **Vmamba:** Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan.<br />
  "Vmamba: Visual state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.10166)]
  [[code](https://github.com/MzeroMiko/VMamba)]

- **Segmamba:** Xing, Zhaohu and Ye, Tian and Yang, Yijun and Liu, Guang and Zhu, Lei.<br />
  "Segmamba: Long-range sequential modeling mamba for 3d medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.13560)]
  [[code]()]

- **U-mamba:** Ma, Jun and Li, Feifei and Wang, Bo.<br />
  "U-mamba: Enhancing long-range dependency for biomedical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.04722)]
  [[code](https://wanglab.ai/u-mamba.html)]

- **H-vmunet:** Wu, Renkai and Liu, Yinghao and Liang, Pengchen and Chang, Qing.<br />
  "H-vmunet: High-order vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.13642)]
  [[code](https://github.com/wurenkai/H-vmunet)]

- **LightM-UNet:** Liao, Weibin and Zhu, Yinghao and Wang, Xinyuan and Pan, Cehngwei and Wang, Yasha and Ma, Liantao.<br />
  "Lightm-unet: Mamba assists in lightweight unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.05246)]
  [[code](https://github.com/MrBlankness/LightM-UNet)]

- **Swin-UMamba:** Liu, Jiarun and Yang, Hao and Zhou, Hong-Yu and Xi, Yan and Yu, Lequan and Yu, Yizhou and Liang, Yong and Shi, Guangming and Zhang, Shaoting and Zheng, Hairong and others.<br />
  "Swin-umamba: Mamba-based unet with imagenet-based pretraining" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.03302)]
  [[code](https://github.com/JiarunLiu/Swin-UMamba)]

- **VM-UNet:** Ruan, Jiacheng and Xiang, Suncheng.<br />
  "Vm-unet: Vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.02491)]
  [[code](https://github.com/JCruan519/VM-UNet)]

- **VM-UNET-V2:** Zhang, Mingya and Yu, Yue and Gu, Limei and Lin, Tingsheng and Tao, Xianping.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.09157)]
  [[code](https://github.com/nobodyplayer1/VM-UNetV2)]

- **LMa-UNet:** Wang, Jinhong and Chen, Jintai and Chen, Danny and Wu, Jian.<br />
  "Large window-based mamba unet for medical image segmentation: Beyond convolution and self-attention" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.07332)]
  [[code](https://github.com/wjh892521292/LMa-UNet)]

- **Mamba-UNet:** Wang, Ziyang and Zheng, Jian-Qing and Zhang, Yichi and Cui, Ge and Li, Lei.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.05079)]
  [[code](https://github.com/ziyangwang007/Mamba-UNet)]

- **TM-UNet:** Tang, Hao and Cheng, Lianglun and Huang, Guoheng and Tan, Zhengguang and Lu, Junhao and Wu, Kaihong.<br />
  "Rotate to scan: Unet-like mamba with triplet ssm module for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.17701)]

- **P-Mamba:** Ye, Zi and Chen, Tianxiang.<br />
  "P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.08506)]
