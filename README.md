# Attention Mechanisms in Medical Image Segmentation: A Survey

> **A Comprehensive Survey on Medical image segmentation.** . [[paper](https://arxiv.org/abs/2305.17937)] [[homepage](https://github.com/Ammexm/Medical-Image-Segmentation)]

> **<p align="justify"> Abstract:** *......* </p>


> **Medical Image Segmentation Models:** A curated list of Medical Image Segmentation models in computer vision and beyond. This repository supplements our survey paper. We intend to continuously update it.
#### If you like our project, please give us a star ‚≠ê on GitHub for latest update.
____

## üòÆ Highlights
```
- 2024.05.27: Latest update of this paper list.
- 2023.05.29: The paper was online.
```
## Contents
- [List of related papers and code](#List-of-related-papers-and-code) 
  - [Pre-Transformer Attention in Medical Segmentation](#Pre-Transformer-Attention-in-Medical-Segmentation)
  - [Transformer in medical Segmentation](#Transformer-in-medical-Segmentation)
  - [Mamba in medical Segmentation](#Mamba-in-medical-Segmentation)
## Citation

If you find our work useful in your research, please consider citing:
```

```

## List of related papers and code
### Pre-Transformer Attention in Medical Segmentation
- **Cell-DETR:** Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz.<br />
  "Attention-based transformers for instance segmentation of cells in microstructures" **IEEE BIBM (2020)**.
  [[paper](https://arxiv.org/pdf/2102.11650)]
  [[code](https://git.rwth-aachen.de/bcs/projects/cell-detr.git)]
  



### Transformer in medical Segmentation
- **Cell-DETR:** Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz.<br />
  "Attention-based transformers for instance segmentation of cells in microstructures" **IEEE BIBM (2020)**.
  [[paper](https://arxiv.org/pdf/2102.11650)]
  [[code](https://git.rwth-aachen.de/bcs/projects/cell-detr.git)]
  
- **TransUNet:** Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L and Zhou, Yuyin.<br />
  "TransUNet:¬†Transformers¬†Make Strong Encoders for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2102.04306)]
  [[code](https://github.com/Beckschen/TransUNet)]

- Karimi, Davood and Vasylechko, Serge Didenko and Gholipour, Ali.<br />
  "Convolution-free medical image segmentation using transformers" **MICCAI  (2021)**.
  [[paper](https://arxiv.org/abs/2102.13645)]
  [[code](https://github.com/Beckschen/TransUNet)]

- **CoTr:** Xie, Yutong and Zhang, Jianpeng and Shen, Chunhua and Xia, Yong.<br />
  "CoTr: Efficiently Bridging CNN and Transformer for 3D Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2103.03024)]
  [[code](https://github.com/YtongXie/CoTr)]

- **SpecTr:** Yun, Boxiang and Wang, Yan and Chen, Jieneng and Wang, Huiyu and Shen, Wei and Li, Qingli.<br />
  "SpecTr: Spectral¬†Transformer¬†for Hyperspectral Pathology Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2103.03604)]
  [[code](https://github.com/hfut-xc-yun/SpecTr)]

- **Medical¬†Transformer:** Jun, Eunji and Jeong, Seungwoo and Heo, Da-Woon and Suk, Heung-Il.<br />
  "Medical¬†Transformer: Universal Brain Encoder for 3D MRI Analysis" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2104.13633)]
  [[code](https://github.com/hfut-xc-yun/SpecTr)]

- **Swin-Unet:** Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning.<br />
  "Swin-Unet: Unet-like Pure¬†Transformer¬†for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2105.05537)]
  [[code](https://github.com/HuCaoFighting/Swin-Unet)]

- **Segtran:** Li, Shaohua and Sui, Xiuchao and Luo, Xiangde and Xu, Xinxing and Liu, Yong and Goh, Rick.<br />
  "Medical Image Segmentation Using Squeeze-and-Expansion¬†Transformers" **IJCAI (2021)**.
  [[paper](https://arxiv.org/abs/2105.09511)]
  [[code](https://github.com/askerlee/segtran)]

- **TransBTS:** Wenxuan, Wang and Chen, Chen and Meng, Ding and Hong, Yu and Sen, Zha and Jiangyun, Li.<br />
  "TransBTS: Multimodal Brain Tumor Segmentation Using¬†Transformer" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2103.04430)]
  [[code](https://github.com/Wenxuan-1119/TransBTS)]

- **MCTrans:** Ji, Yuanfeng and Zhang, Ruimao and Wang, Huijie and Li, Zhen and Wu, Lingyun and Zhang, Shaoting and Luo, Ping.<br />
  "Multi-Compound¬†Transformer¬†for Accurate Biomedical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2106.14385)]
  [[code](https://github.com/JiYuanFeng/MCTrans)

- **MedT:** Valanarasu, Jeya Maria Jose and Oza, Poojan and Hacihaliloglu, Ilker and Patel, Vishal M.<br />
  "Medical¬†Transformer: Gated Axial-Attention for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2102.10662)]
  [[code](https://github.com/jeya-maria-jose/Medical-Transformer)]

- **TransFuse:** Zhang, Yundong and Liu, Huiye and Hu, Qiang.<br />
  "TransFuse: Fusing¬†Transformers¬†and CNNs for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2102.08005)]

- **TransClaw U-Net:** Yao, Chang and Hu, Menghan and Li, Qingli and Zhai, Guangtao and Zhang, Xiao-Ping.<br />
  "TransClaw U-Net: Claw U-Net with¬†Transformers¬†for Medical Image Segmentation" **ICICSP (2022)**.
  [[paper](https://arxiv.org/abs/2107.05188)]

- **TransAttUnet:** Chen, Bingzhi and Liu, Yishu and Zhang, Zheng and Lu, Guangming and Kong, Adams Wai Kin.<br />
  "TransAttUnet: Multi-level Attention-guided U-Net with¬†Transformer¬†for Medical Image Segmentation" **TETCI (2023)**.
  [[paper](https://arxiv.org/abs/2107.05274)]
  [[code](https://github.com/YishuLiu/TransAttUnet)]

- **LeViT-UNet:** Xu, Guoping and Zhang, Xuan and He, Xinwei and Wu, Xinglong.<br />
  "LeViT-UNet: Make Faster Encoders with¬†Transformer¬†for Medical Image Segmentation" **PRCV (2023)**.
  [[paper](https://arxiv.org/abs/2107.08623)]
  [[code](https://github.com/apple1986/LeViT_UNet)]

- **Polyp-PVT:** Dong, Bo and Wang, Wenhai and Fan, Deng-Ping and Li, Jinpeng and Fu, Huazhu and Shao, Ling.<br />
  "Polyp-PVT: Polyp Segmentation with Pyramid Vision¬†Transformers" **CAAI AIR (2023)**.
  [[paper](https://arxiv.org/abs/2108.06932)]
  [[code](https://github.com/DengPingFan/Polyp-PVT)]

- **PMTrans:** Zhang, Zhuangzhuang and Zhang, Weixiong.<br />
  "Pyramid Medical¬†Transformer¬†for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2104.14702)]

- **MISSFormer:** Huang, Xiaohong and Deng, Zhifang and Li, Dandan and Yuan, Xueguang.<br />
  "MISSFormer: An Effective Medical Image Segmentation¬†Transformer" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.07162)]
  [[code](https://github.com/ZhifangDeng/MISSFormer)]

- **TUnet:** Sha, Youyang and Zhang, Yonghong and Ji, Xuquan and Hu, Lei.<br />
  "Transformer-Unet: Raw Image Processing with Unet" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.08417)]

- **BiTr-Unet:** Jia, Qiran and Shu, Hai.<br />
  "BiTr-Unet: a CNN-Transformer¬†Combined Network for MRI Brain Tumor Segmentation" **International MICCAI Brainlesion Workshop (2021)**.
  [[paper](https://arxiv.org/abs/2109.12271)]
  [[code](https://github.com/JustaTinyDot/BiTr-Unet)]

- **UTNet:** Gao, Yunhe and Zhou, Mu and Metaxas, Dimitris N.<br />
  "UTNet: A Hybrid¬†Transformer¬†Architecture for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2107.00781)]
  [[code](https://github.com/yhygao/UTNet)]

- **GT U-Net:** Li, Yunxiang and Wang, Shuai and Wang, Jun and Zeng, Guodong and Liu, Wenjun and Zhang, Qianni and Jin, Qun and Wang, Yaqi.<br />
  "GT U-Net: A U-Net Like Group¬†Transformer¬†Network for Tooth Root Segmentation" **International Workshop on MIMI (2021)**.
  [[paper](https://arxiv.org/abs/2109.14813)]
  [[code](https://github.com/Kent0n-Li/GT-U-Net)]

- **nnFormer:** Zhou, Hong-Yu and Guo, Jiansen and Zhang, Yinghao and Yu, Lequan and Wang, Liansheng and Yu, Yizhou.<br />
  "nnFormer: Interleaved¬†Transformer¬†for Volumetric Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.03201)]
  [[code](https://git.io/JSf3i)]

- Pandey, Deepanshu and Gupta, Pradyumna and Bhattacharya, Sumit and Sinha, Aman and Agarwal, Rohit.<br />
  "Transformer¬†Assisted Convolutional Network for Cell Instance Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.02270)]
  [[code](https://github.com/dsciitism/SegPC-2021)]

- **BAT:** Wang, Jiacheng and Wei, Lan and Wang, Liansheng and Zhou, Qichao and Zhu, Lei and Qin, Jing.<br />
  "Boundary-aware¬†Transformers¬†for Skin Lesion Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2110.03864)]
  [[code](https://github.com/jcwang123/BA-Transformer)]

- **UNETR:** Hatamizadeh, Ali and Tang, Yucheng and Nath, Vishwesh and Yang, Dong and Myronenko, Andriy and Landman, Bennett and Roth, Holger R and Xu, Daguang.<br />
  "UNETR:¬†Transformers¬†for 3D Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://arxiv.org/abs/2103.10504)]
  [[code](https://monai.io/research/unetr)]

- Dobko, Mariia and Kolinko, Danylo-Ivan and Viniavskyi, Ostap and Yelisieiev, Yurii.<br />
  "Combining CNNs With¬†Transformer¬†for Multimodal 3D MRI Brain Tumor Segmentation With Self-Supervised Pretraining" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.07919)]
  [[code](https://github.com/ucuapps/BraTS2021_Challenge)]

- **Bilateral-ViT:** Song, Sifan and Dang, Kang and Yu, Qinji and Wang, Zilong and Coenen, Frans and Su, Jionglong and Ding, Xiaowei.<br />
  "Bilateral-ViT for Robust Fovea Localization" **ISBI (2022)**.
  [[paper](https://arxiv.org/abs/2110.09860)]

- **BiTrans:** Wei, Jianze and Huang, Huaibo and Sun, Muyi and Wang, Yunlong and Ren, Min and He, Ran and Sun, Zhenan.<br />
  "Toward Accurate and Reliable Iris Segmentation Using Uncertainty Learning" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.10334)]

- **AFTer-UNet:** Yan, Xiangyi and Tang, Hao and Sun, Shanlin and Ma, Haoyu and Kong, Deying and Xie, Xiaohui.<br />
  "AFTer-UNet: Axial Fusion¬†Transformer¬†UNet for Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://arxiv.org/abs/2110.10403)]

- **DTNet:** Li, Yunxiang and Li, Jingxiong and Dan, Ruilong and Wang, Shuai and Jin, Kai and Zeng, Guodong and Wang, Jun and Pan, Xiangji and Zhang, Qianni and Zhou, Huiyu and others.<br />
  "Dispensed¬†Transformer¬†Network for Unsupervised Domain Adaptation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.14944)]
  [[code](https://github.com/Kent0n-Li/DTNet)]

- **MT-UNet:** Wang, Hongyi and Xie, Shiao and Lin, Lanfen and Iwamoto, Yutaro and Han, Xian-Hua and Chen, Yen-Wei and Tong, Ruofeng.<br />
  "Mixed¬†Transformer¬†U-Net For Medical Image Segmentation" **ICASSP (2022)**.
  [[paper](https://arxiv.org/abs/2111.04734)]
  [[code](https://github.com/Dootmaan/MT-UNet)]

- **VT-UNet:** Peiris, H and Hayat, M and Chen, Z and Egan, G and Harandi, M.<br />
  "A Volumetric¬†Transformer¬†for Accurate 3D Tumor Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2111.13300)]
  [[code](https://github.com/himashi92/VT-UNet)]

- Tang, Yucheng and Yang, Dong and Li, Wenqi and Roth, Holger R and Landman, Bennett and Xu, Daguang and Nath, Vishwesh and Hatamizadeh, Ali.<br />
  "Self-Supervised Pre-Training of Swin¬†Transformers¬†for 3D Medical Image Analysis" **CVPR (2022)**.
  [[paper](https://arxiv.org/abs/2111.14791)]
  [[code](https://monai.io/research/swin-unetr)]

- **UCTransNet:** Wang, Haonan and Cao, Peng and Wang, Jiaqi and Zaiane, Osmar R.<br />
  "UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer" **AAAI (2022)**.
  [[paper](https://arxiv.org/abs/2109.04335)]
  [[code](https://github.com/McGregorWwww/UCTransNet)]

- **Swin UNETR:** Hatamizadeh, Ali and Nath, Vishwesh and Tang, Yucheng and Yang, Dong and Roth, Holger R and Xu, Daguang.<br />
  "Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images" **International MICCAI Brainlesion Workshop (2021)**.
  [[paper](https://arxiv.org/abs/2201.01266)]
  [[code](https://monai.io/research/swin-unetr)]

- **ViTBIS:** Sagar, Abhinav.<br />
  "ViTBIS: Vision Transformer for Biomedical Image Segmentation" **MICCAI Workshop on Distributed and Collaborative Learning (2021)**.
  [[paper](https://arxiv.org/abs/2201.05920)]

- **TransBTSV2:** Li, Jiangyun and Wang, Wenxuan and Chen, Chen and Zhang, Tianxiang and Zha, Sen and Yu, Hong and Wang, Jing.<br />
  "TransBTSV2: Wider Instead of Deeper Transformer for Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2201.12785)]
  [[code](https://github.com/Wenxuan-1119/TransBTS)]

- **SSFormer:** Wang, Jinfeng and Huang, Qiming and Tang, Feilong and Meng, Jia and Su, Jionglong and Song, Sifan.<br />
  "Stepwise Feature Fusion: Local Guides Global" **MICCAI (2022)**.
  [[paper](https://arxiv.org/abs/2203.03635)]
  [[code](https://github.com/Qiming-Huang/ssformer)]

- **SwinBTS:** Jiang, Yun and Zhang, Yuan and Lin, Xin and Dong, Jinkun and Cheng, Tongtong and Liang, Jing.<br />
  "SwinBTS: A method for 3D multimodal brain tumor¬†segmentation¬†using swin¬†transformer" **Brain sciences (2022)**.
  [[paper](https://www.mdpi.com/2076-3425/12/6/797/pdf)]
  [[code](https://github.com/langwangdezhexue/Swin_BTS)]

- **3D PSwinBTS:** Liang, Junjie and Yang, Cihui and Zeng, Lingguo.<br />
  "3D PSwinBTS: An efficient¬†transformer-based Unet using 3D parallel shifted windows for brain tumor¬†segmentation" **Digital Signal Processing (2022)**.

- **TranSiam:** Li, Xuejian and Ma, Shiqiang and Tang, Jijun and Guo, Fei.<br />
  "TranSiam: Fusing Multimodal Visual Features Using¬†Transformer¬†for¬†Medical¬†Image¬†Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2204.12185)]

- **BTSwin-Unet:** Liang, Junjie and Yang, Cihui and Zhong, Jingting and Ye, Xiaoli.<br />
  "BTSwin-Unet: 3D U-shaped Symmetrical Swin¬†Transformer-based Network for Brain Tumor¬†Segmentation¬†with Self-supervised Pre-trainin" **Neural processing letters (2023)**.

- **TransConver:** Liang, Junjie and Yang, Cihui and Zeng, Mengjie and Wang, Xixi.<br />
  "TransConver: transformer and convolution parallel network for developing automatic brain tumor segmentation in MRI images" **Quantitative Imaging in Medicine and Surgery (2022)**.
  [[paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8923874/)]

- **FCBFormer:** Sanderson, Edward and Matuszewski, Bogdan J.<br />
  "FCN-transformer feature fusion for polyp segmentation" **MIUA (2022)**.
  [[paper](https://link.springer.com/content/pdf/10.1007/978-3-031-12053-4_65.pdf)]
  [[code](https://github.com/CVML-UCLan/FCBFormer)]

- **SwinE-Net:** Park, Kyeong-Beom and Lee, Jae Yeol.<br />
  "SwinE-Net: hybrid deep learning approach to novel polyp segmentation using convolutional neural network and Swin Transformer" **Journal of Computational Design and Engineering (2022)**.
  [[paper](https://academic.oup.com/jcde/article-pdf/9/2/616/43298266/qwac018.pdf10.1007/978-3-031-12053-4_65.pdf)]

- **PCAT-UNet:** Chen, Danny and Yang, Wenzhong and Wang, Liejun and Tan, Sixiang and Lin, Jiangzhaung and Bu, Wenxiu.<br />
  "PCAT-UNet: UNet-like network fused convolution and transformer for retinal vessel segmentation" **PloS one (2022)**.
  [[paper](https://doi.org/10.1371/journal.pone.0262689)]

- **RTN:** Huang, Shiqi and Li, Jianan and Xiao, Yuze and Shen, Ning and Xu, Tingfa.<br />
  "RTNet: Relation transformer network for diabetic retinopathy multi-lesion segmentation" **IEEE Trans Med Imaging (2022)**.
  [[paper](https://arxiv.org/pdf/2201.11037)]

- **MTPA_Unet:** Jiang, Yun and Liang, Jing and Cheng, Tongtong and Lin, Xin and Zhang, Yuan and Dong, Jinkun.<br />
  "MTPA_Unet: Multi-Scale Transformer-Position Attention Retinal Vessel Segmentation Network Joint Transformer and CNN" **Sensors (2022)**.
  [[paper](https://www.mdpi.com/1424-8220/22/12/4592)]

- **UNetFormer:** Hatamizadeh, Ali and Xu, Ziyue and Yang, Dong and Li, Wenqi and Roth, Holger and Xu, Daguang.<br />
  "UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2204.00631)]
  [[code](https://github.com/Project-MONAI/research-contributions)]

- **D-former:** Wu, Yixuan and Liao, Kuanlun and Chen, Jintai and Wang, Jinhong and Chen, Danny Z and Gao, Honghao and Wu, Jian.<br />
  "D-former: A u-shaped dilated transformer for 3d medical image segmentation" **Neural Computing and Applications (2023)**.
  [[paper](https://arxiv.org/abs/2201.00462)]

- **UTNetV2:** Gao, Yunhe and Zhou, Mu and Liu, Di and Metaxas, Dimitris.<br />
  "A Multi-scale Transformer for Medical Image Segmentation: Architectures, Model Efficiency, and Benchmarks" **arXiv (2022)**.
  [[paper](https://www.semanticscholar.org/paper/A-Multi-scale-Transformer-for-Medical-Image-Model-Gao-Zhou/83cefdeb36c001550e3c0e0c45d10d4b80485229)]

- **DSTUNet:** Cai, Zhuotong and Xin, Jingmin and Shi, Peiwen and Wu, Jiayi and Zheng, Nanning.<br />
  "DSTUNet: UNet with Efficient Dense SWIN Transformer Pathway for Medical Image Segmentation" **ISBI (2022)**.

- **CASTformer:** You, Chenyu and Zhao, Ruihan and Liu, Fenglin and Dong, Siyuan and Chinchali, Sandeep and Topcu, Ufuk and Staib, Lawrence and Duncan, James.<br />
  "Class-Aware Generative Adversarial Transformers for Medical Image Segmentation" **NeurIPS (2022)**.
  [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/be99227ef4a4de84bb45d7dc7b53f808-Paper-Conference.pdf)]

- Gao, Yunhe and Zhou, Mu and Liu, Di and Yan, Zhennan and Zhang, Shaoting and Metaxas, Dimitris N.<br />
  "A Data-scalable Transformer for Medical Image Segmentation: Architecture, Model Efficiency, and Benchmark" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2203.00131)]

- **mmFormer:** Zhang, Yao and He, Nanjun and Yang, Jiawei and Li, Yuexiang and Wei, Dong and Huang, Yawen and Zhang, Yang and He, Zhiqiang and Zheng, Yefeng.<br />
  "mmFormer: Multimodal Medical Transformer for Incomplete Multimodal Learning of Brain Tumor Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2206.02425)]
  [[code](https://github.com/YaoZhang93/mmFormer)]

- **ColonFormer:** Duc, Nguyen Thanh and Oanh, Nguyen Thi and Thuy, Nguyen Thi and Triet, Tran Minh and Dinh, Viet Sang.<br />
  "ColonFormer: An Efficient Transformer based Method for Colon Polyp Segmentation" **IEEE Access (2022)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/09845389.pdf)]
  [[code](https://github.com/ducnt9907/ColonFormer)]

- **FCT:** Tragakis, Athanasios and Kaul, Chaitanya and Murray-Smith, Roderick and Husmeier, Dirk.<br />
  "The Fully Convolutional Transformer for Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Tragakis_The_Fully_Convolutional_Transformer_for_Medical_Image_Segmentation_WACV_2023_paper.pdf)]
  [[code](https://github.com/Thanos-DB/)]

- **Patcher:** Ou, Yanglan and Yuan, Ye and Huang, Xiaolei and Wong, Stephen TC and Volpi, John and Wang, James Z and Wong, Kelvin.<br />
  "Patcher: Patch Transformers with Mixture of Experts for Precise Medical Image Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2206.01741)]
  [[code](https://github.com/YanglanOu/patcher.git)]

- **UniMiSS:** Xie, Yutong and Zhang, Jianpeng and Xia, Yong and Wu, Qi.<br />
  "UniMiSS: Universal Medical Self-Supervised Learning via Breaking Dimensionality Barrier" **ECCV (2022)**.
  [[paper](https://arxiv.org/pdf/2112.09356)]
  [[code](https://github.com/YtongXie/UniMiSS-code)]

- **TransResU-Net:** Tomar, Nikhil Kumar and Shergill, Annie and Rieders, Brandon and Bagci, Ulas and Jha, Debesh.<br />
  "TransResU-Net: Transformer based ResU-Net for Real-Time Colonoscopy Polyp Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2206.08985)]
  [[code](https://github.com/nikhilroxtomar/TransResUNet)]

- **LViT:** Li, Zihan and Li, Yunxiang and Li, Qingde and Wang, Puyang and Guo, Dazhou and Lu, Le and Jin, Dakai and Zhang, You and Hong, Qingqi.<br />
  "LViT: Language meets Vision Transformer in Medical Image Segmentation" **IEEE Trans Med Imaging (2023)**.
  [[paper](https://arxiv.org/pdf/2206.14718)]
  [[code](https://github.com/HUANGLIZI/LViT)]

- **HiFormer:** Heidari, Moein and Kazerouni, Amirhossein and Soltany, Milad and Azad, Reza and Aghdam, Ehsan Khodapanah and Cohen-Adad, Julien and Merhof, Dorit.<br />
  "HiFormer: Hierarchical Multi-scale Representations Using Transformers for Medical Image Segmentation" **WACV (2023)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Heidari_HiFormer_Hierarchical_Multi-Scale_Representations_Using_Transformers_for_Medical_Image_Segmentation_WACV_2023_paper.pdf)]
  [[code](https://github.com/amirhossein-kz/HiFormer)]

- **NestedFormer:** Xing, Zhaohu and Yu, Lequan and Wan, Liang and Han, Tong and Zhu, Lei.<br />
  "NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2208.14876)]
  [[code](https://github.com/920232796/NestedFormer)]

- **CR-Swin2-VT:** Peiris, Himashi and Hayat, Munawar and Chen, Zhaolin and Egan, Gary and Harandi, Mehrtash.<br />
  "Hybrid Window Attention Based Transformer Architecture for Brain Tumor Segmentation" **International MICCAI Brainlesion Workshop (2022)**.
  [[paper](https://arxiv.org/pdf/2209.07704)]
  [[code](https://github.com/himashi92/vizviva_fets_2022)]

- Huang, Junjia and Li, Haofeng and Li, Guanbin and Wan, Xiang.<br />
  "Attentive Symmetric Autoencoder for Brain MRI Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2209.08887)]

- **UNesT:** Yu, Xin and Yang, Qi and Zhou, Yinchi and Cai, Leon Y and Gao, Riqiang and Lee, Ho Hin and Li, Thomas and Bao, Shunxing and Xu, Zhoubing and Lasko, Thomas A and others.<br />
  "UNesT: Local Spatial Representation Learning with Hierarchical Transformer for Efficient Medical Segmentation" **Medical Image Analysis (2023)**.
  [[paper](https://arxiv.org/pdf/2209.14378)]
  [[code](https://github.com/MASILab/UNesT)]

- **FINE:** Themyr, Loic and Rambour, Cl{\'e}ment and Thome, Nicolas and Collins, Toby and Hostettler, Alexandre.<br />
  "Memory transformers for full context and high-resolution 3D Medical Segmentation" **International Workshop on Machine Learning in Medical Imaging (2022)**.
  [[paper](https://arxiv.org/pdf/2210.05313)]

- **CTS:** Gong, Zhendi and French, Andrew P and Qiu, Guoping and Chen, Xin.<br />
  "ConvTransSeg: A Multi-resolution Convolution-Transformer Network for Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2210.07072)]

- **CS-Unet:** Liu, Qianying and Kaul, Chaitanya and Wang, Jun and Anagnostopoulos, Christos and Murray-Smith, Roderick and Deligianni, Fani.<br />
  "Optimizing Vision Transformers for Medical Image Segmentation" **ICASSP (2023)**.
  [[paper](https://arxiv.org/pdf/2210.08066)]
  [[code](https://github.com/kathyliu579/CS-Unet)]

- **MEW-UNET:** Ruan, Jiacheng and Xie, Mingye and Xiang, Suncheng and Liu, Ting and Fu, Yuzhuo.<br />
  "MEW-UNET: MULTI-AXIS REPRESENTATION LEARNING IN FREQUENCY DOMAIN FOR MEDICAL IMAGE SEGMENTATION" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2210.14007)]
  [[code](https://github.com/JCruan519/MEW-UNet)]

- Li, Yijiang and Cai, Wentian and Gao, Ying and Li, Chengming and Hu, Xiping.<br />
  "More than Encoder: Introducing Transformer Decoder to Upsample" **IEEE BIBM (2022)**.
  [[paper](https://arxiv.org/pdf/2106.10637)]

- **UNETR++:** Shaker, Abdelrahman M and Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Yang, Ming-Hsuan and Khan, Fahad Shahbaz.<br />
  "UNETR++: Delving into Efficient and Accurate 3D Medical Image Segmentation" **IEEE Trans Med Imaging (2024)**.
  [[paper](https://ieeexplore.ieee.org/iel7/42/4359023/10526382.pdf)]
  [[code](https://tinyurl.com/2p87x5xn)]
  
- **DAE-Former:** Azad, Reza and Arimond, Ren{\'e} and Aghdam, Ehsan Khodapanah and Kazerouni, Amirhossein and Merhof, Dorit.<br />
  "DAE-Former: Dual Attention-guided Efficient Transformer for Medical Image Segmentation" **International Workshop on PRedictive Intelligence In MEdicine (2023)**.
  [[paper](https://arxiv.org/pdf/2212.13504)]
  [[code](https://github.com/mindflow-institue/DAEFormer)]

- **TransCeption:** Azad, Reza and Jia, Yiwei and Aghdam, Ehsan Khodapanah and Cohen-Adad, Julien and Merhof, Dorit.<br />
  "Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2301.10847)]
  [[code](https://github.com/mindflow-institue/TransCeption)]

- **MAXVIT-UNET:** Khan, Abdul Rehman and Khan, Asifullah.<br />
  "MAXVIT-UNET: MULTI-AXIS ATTENTION FOR MEDICAL IMAGE SEGMENTATION" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2305.08396)]
  [[code](https://github.com/PRLAB21/MaxViT-UNet)]

- **MIST:** Rahman, Md Motiur and Shokouhmand, Shiva and Bhatt, Smriti and Faezipour, Miad.<br />
  "MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder" **WACV (2024)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2024/papers/Rahman_MIST_Medical_Image_Segmentation_Transformer_With_Convolutional_Attention_Mixing_CAM_WACV_2024_paper.pdf)]
  [[code](https://github.com/Rahman-Motiur/MIST)]

- **MS-Twins:** Xu, Jing.<br />
  "MS-TwinsÔºöMulti-Scale Deep Self-Attention Networks for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2312.07128)]

- **Cascaded MERIT:** Rahman, Md Mostafijur and Marculescu, Radu.<br />
  "Multi-scale hierarchical vision transformer with cascaded attention decoding for medical image segmentation" **MIDL (2024)**.
  [[paper](https://proceedings.mlr.press/v227/rahman24a/rahman24a.pdf)]
  [[code](https://github.com/SLDGroup/MERIT)]

- Rahman, Md Mostafijur and Marculescu, Radu.<br />
  "Medical image segmentation via cascaded attention decoding" **WACV (2023)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.pdf)]
  [[code](https://github.com/SLDGroup/MERIT)]

- **D-TrAttUnet:** Bougourzi, Fares and Dornaika, Fadi and Distante, Cosimo and Taleb-Ahmed, Abdelmalik.<br />
  "D-TrAttUnet: Toward Hybrid CNN-Transformer Architecture for Generic and Subtle Segmentation in Medical Images" **Computers in Biology and Medicine (2024)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0010482524006759)]
  [[code](https://github.com/faresbougourzi/D-TrAttUnet)]

- **PAGTransYnet:** Bougourzi, Fares and Dornaika, Fadi and Taleb-Ahmed, Abdelmalik and Hoang, Vinh Truong.<br />
  "Rethinking Attention Gated with Hybrid Dual Pyramid Transformer-CNN for Generalized Segmentation in Medical Imaging" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.18199)]
  [[code](https://github.com/faresbougourzi/PAGTransYnet)]

- **PAG-TransYnet:** Bougourzi, Fares and Dornaika, Fadi and Taleb-Ahmed, Abdelmalik and Hoang, Vinh Truong.<br />
  "Rethinking Attention Gated with Hybrid Dual Pyramid Transformer-CNN for Generalized Segmentation in Medical Imaging" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.18199)]
  [[code](https://github.com/faresbougourzi/PAGTransYnet)]

- **SegFormer3D:** Perera, Shehan and Navard, Pouyan and Yilmaz, Alper.<br />
  "SegFormer3D: an Efficient Transformer for 3D Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.10156)]
  [[code](https://github.com/OSUPCVLab/SegFormer3D.git)]

- **3D-EffiViTCaps:** Gan, Dongwei and Chang, Ming and Chen, Juan.<br />
  "3D-EffiViTCaps: 3D Efficient Vision Transformer with Capsule for Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2403.16350)]
  [[code](https://github.com/HidNeuron/3D-EffiViTCaps)]

- **BEFUnet:** Manzari, Omid Nejati and Kaleybar, Javad Mirzapour and Saadat, Hooman and Maleki, Shahin.<br />
  "BEFUnet: A Hybrid CNN-Transformer Architecture for Precise Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2402.08793)]
  [[code](https://github.com/Omid-Nejati/BEFUnet)]

- **ScribFormer:** Li, Zihan and Zheng, Yuan and Shan, Dandan and Yang, Shuzhou and Li, Qingde and Wang, Beizhan and Zhang, Yuanting and Hong, Qingqi and Shen, Dinggang.<br />
  "ScribFormer: Transformer Makes CNN Work Better for Scribble-based Medical Image Segmentation" **IEEE Trans Med Imaging (2024)**.
  [[paper](https://arxiv.org/html/2402.02029v1)]
  [[code](https://github.com/HUANGLIZI/ScribFormer)]

- **MOSformer:** Huang, De-Xing and Zhou, Xiao-Hu and Xie, Xiao-Liang and Liu, Shi-Qi and Feng, Zhen-Qiu and Gui, Mei-Jiang and Li, Hao and Xiang, Tian-Yu and Liu, Xiu-Ling and Hou, Zeng-Guang.<br />
  "MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2401.11856)]

- **BRAU-Net++:** Lan, Libin and Cai, Pengzhou and Jiang, Lu and Liu, Xiaojuan and Li, Yongmei and Zhang, Yudong.<br />
  "BRAU-Net++: U-Shaped Hybrid CNN-Transformer Network for Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2401.00722)]
  [[code](https://github.com/Caipengzhou/BRAU-Netplusplus)]

- **MobileUtr:** Tang, Fenghe and Nian, Bingkun and Ding, Jianrui and Quan, Quan and Yang, Jie and Liu, Wei and Zhou, S Kevin.<br />
  "MobileUtr: Revisiting the relationship between light-weight CNN and Transformer for efficient medical image segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/abs/2312.01740)]
  [[code](https://github.com/FengheTan9/MobileUtr)]

- **DA-TransUNet:** Sun, Guanqun and Pan, Yizhi and Kong, Weikun and Xu, Zichang and Ma, Jianhua and Racharak, Teeradaj and Nguyen, Le-Minh.<br />
  "DA-TransUNet: Integrating Spatial and Channel Dual Attention with Transformer U-Net for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.12570)]
  [[code](https://github.com/SUN-1024/DA-TransUnet)]

- **SeUNet-Trans:** Pham, Tan-Hanh and Li, Xianqi and Nguyen, Kim-Doang.<br />
  "SeUNet-Trans: A Simple yet Effective UNet-Transformer Model for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.09998)]

- **3D-TransUNet:** Chen, Jieneng and Mei, Jieru and Li, Xianhang and Lu, Yongyi and Yu, Qihang and Wei, Qingyue and Luo, Xiangde and Xie, Yutong and Adeli, Ehsan and Wang, Yan and others.<br />
  "3D TransUNet: Advancing Medical Image Segmentation through Vision Transformers" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.07781)]
  [[code](https://github.com/Beckschen/3D-TransUNet)]

- **C-ViT:** Bastico, Matteo and Ryckelynck, David and Cort{\'e}, Laurent and Tillier, Yannick and Decenci{\`e}re, Etienne.<br />
  "A Simple and Robust Framework for Cross-Modality Medical Image Segmentation applied to Vision Transformers" **ICCV (2023)**.
  [[paper](https://openaccess.thecvf.com/content/ICCV2023W/LXCV/papers/Bastico_A_Simple_and_Robust_Framework_for_Cross-Modality_Medical_Image_Segmentation_ICCVW_2023_paper.pdf)]
  [[code](https://github.com/matteo-bastico/MI-Seg)]

- **ConvFormer:** Lin, Xian and Yan, Zengqiang and Deng, Xianbo and Zheng, Chuansheng and Yu, Li.<br />
  "ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2309.05674)]
  [[code](https://github.com/xianlin7/ConvFormer)]

- **SwinMM:** Wang, Yiqing and Li, Zihan and Mei, Jieru and Wei, Zihao and Liu, Li and Wang, Chen and Sang, Shengtian and Yuille, Alan L and Xie, Cihang and Zhou, Yuyin.<br />
  "SwinMM: Masked Multi-view with Swin Transformers for 3D Medical Image Segmentation" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2307.12591)]
  [[code](https://github.com/UCSC-VLAA/SwinMM/)]

- **MDViT:** Du, Siyi and Bayasi, Nourhan and Hamarneh, Ghassan and Garbi, Rafeef.<br />
  "MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2307.02100)]
  [[code](https://github.com/siyi-wind/MDViT)]

- **TEC-Net:** Lei, Tao and Sun, Rui and Wan, Yong and Xia, Yong and Du, Xiaogang and Nandi, Asoke K.<br />
  "TEC-Net: Vision Transformer Embrace Convolutional Neural Networks for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2306.04086)]
  [[code](https://github.com/SR0920/TECNet)]

- **CiT-Net:** Lei, Tao and Sun, Rui and Wang, Xuan and Wang, Yingbo and He, Xi and Nandi, Asoke.<br />
  "CiT-Net: Convolutional Neural Networks Hand in Hand with Vision Transformers for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2306.03373)]
  [[code](https://github.com/SR0920/CiT-Net)]

- **TAB:** Liao, Zehui and Hu, Shishuai and Xie, Yutong and Xia, Yong.<br />
  "Transformer-based Annotation Bias-aware Medical Image Segmentation" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2306.01340)]

- Saeed, Numan and Ridzuan, Muhammad and Majzoub, Roba Al and Yaqub, Mohammad.<br />
  "Prompt-Based Tuning of Transformer Models for Multi-Center Medical Image Segmentation of Head and Neck Cancer" **Bioengineering (2023)**.
  [[paper](https://arxiv.org/abs/2305.18948)]

- **STM-UNet:** Shi, Lei and Gao, Tianyu and Zhang, Zheng and Zhang, Junxing.<br />
  "STM-UNet: An Efficient U-shaped Architecture Based on Swin Transformer and Multi-scale MLP for Medical Image Segmentation" **IEEE GLOBECOM (2023)**.
  [[paper](https://arxiv.org/pdf/2304.12615)]

- **Dilated-UNet:** Saadati, Davoud and Manzari, Omid Nejati and Mirzakuchaki, Sattar.<br />
  "Dilated-UNet: A Fast and Accurate Medical Image Segmentation Approach using a Dilated Transformer and U-Net Architecture" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2304.11450)]
  [[code](https://github.com/Omid-Nejati/Dilated_Unet)]

- **HST-MRF:** Huang, Xiaofei and Gong, Hongfang and Zhang, Jin.<br />
  "HST-MRF: Heterogeneous Swin Transformer with Multi-Receptive Field for Medical Image Segmentation" **IEEE Journal of Biomedical and Health Informatics (2024)**.
  [[paper](https://arxiv.org/pdf/2304.04614)]

- **U-Netmer:** He, Sheng and Bao, Rina and Grant, P Ellen and Ou, Yangming.<br />
  "U-Netmer:U-NetmeetsTransformer formedical imagesegmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2304.01401)]

- Yuan, Mingze and Xia, Yingda and Dong, Hexin and Chen, Zifan and Yao, Jiawen and Qiu, Mingyan and Yan, Ke and Yin, Xiaoli and Shi, Yu and Chen, Xin and others.<br />
  "Devil is in the Queries: Advancing Mask Transformers for Real-world Medical Image Segmentation and Out-of-Distribution Localization" **CVPR (2023)**.
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Yuan_Devil_Is_in_the_Queries_Advancing_Mask_Transformers_for_Real-World_CVPR_2023_paper.pdf)]


### Mamba in medical Segmentation
- **Mamba:** Gu, Albert and Dao, Tri.<br />
  "Mamba: Linear-Time Sequence Modeling with Selective State Spaces" **arXiv (2023)**.
  [[paper](https://arxiv.org/abs/2312.00752)] 

- **Vim:** Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang.<br />
  "Vision mamba: Efficient visual representation learning with bidirectional state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.09417)] 

- **Vmamba:** Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan.<br />
  "Vmamba: Visual state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.10166)]
  [[code](https://github.com/MzeroMiko/VMamba)]

- **Segmamba:** Xing, Zhaohu and Ye, Tian and Yang, Yijun and Liu, Guang and Zhu, Lei.<br />
  "Segmamba: Long-range sequential modeling mamba for 3d medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.13560)]
  [[code]()]

- **U-mamba:** Ma, Jun and Li, Feifei and Wang, Bo.<br />
  "U-mamba: Enhancing long-range dependency for biomedical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.04722)]
  [[code](https://wanglab.ai/u-mamba.html)]

- **H-vmunet:** Wu, Renkai and Liu, Yinghao and Liang, Pengchen and Chang, Qing.<br />
  "H-vmunet: High-order vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.13642)]
  [[code](https://github.com/wurenkai/H-vmunet)]

- **LightM-UNet:** Liao, Weibin and Zhu, Yinghao and Wang, Xinyuan and Pan, Cehngwei and Wang, Yasha and Ma, Liantao.<br />
  "Lightm-unet: Mamba assists in lightweight unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.05246)]
  [[code](https://github.com/MrBlankness/LightM-UNet)]

- **Swin-UMamba:** Liu, Jiarun and Yang, Hao and Zhou, Hong-Yu and Xi, Yan and Yu, Lequan and Yu, Yizhou and Liang, Yong and Shi, Guangming and Zhang, Shaoting and Zheng, Hairong and others.<br />
  "Swin-umamba: Mamba-based unet with imagenet-based pretraining" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.03302)]
  [[code](https://github.com/JiarunLiu/Swin-UMamba)]

- **VM-UNet:** Ruan, Jiacheng and Xiang, Suncheng.<br />
  "Vm-unet: Vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.02491)]
  [[code](https://github.com/JCruan519/VM-UNet)]

- **VM-UNET-V2:** Zhang, Mingya and Yu, Yue and Gu, Limei and Lin, Tingsheng and Tao, Xianping.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.09157)]
  [[code](https://github.com/nobodyplayer1/VM-UNetV2)]

- **LMa-UNet:** Wang, Jinhong and Chen, Jintai and Chen, Danny and Wu, Jian.<br />
  "Large window-based mamba unet for medical image segmentation: Beyond convolution and self-attention" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.07332)]
  [[code](https://github.com/wjh892521292/LMa-UNet)]

- **Mamba-UNet:** Wang, Ziyang and Zheng, Jian-Qing and Zhang, Yichi and Cui, Ge and Li, Lei.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.05079)]
  [[code](https://github.com/ziyangwang007/Mamba-UNet)]

- **TM-UNet:** Tang, Hao and Cheng, Lianglun and Huang, Guoheng and Tan, Zhengguang and Lu, Junhao and Wu, Kaihong.<br />
  "Rotate to scan: Unet-like mamba with triplet ssm module for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.17701)]

- **P-Mamba:** Ye, Zi and Chen, Tianxiang.<br />
  "P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.08506)]
