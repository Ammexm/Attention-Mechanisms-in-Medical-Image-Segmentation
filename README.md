# Attention Mechanisms in Medical Image Segmentation: A Survey

> **A Comprehensive Survey on Medical image segmentation.** . [[paper](https://arxiv.org/abs/2305.17937)] [[homepage](https://github.com/Ammexm/Medical-Image-Segmentation)]

> **<p align="justify"> Abstract:** *......* </p>


> **Medical Image Segmentation Models:** A curated list of Medical Image Segmentation models in computer vision and beyond. This repository supplements our survey paper. We intend to continuously update it.
#### If you like our project, please give us a star ‚≠ê on GitHub for latest update.
____

## üòÆ Highlights
```
- 2024.06.011: Latest update of this paper list.
- 2023.05.29: The paper was online.
```
## Contents
- [List of related papers and code](#List-of-related-papers-and-code) 
  - [Pre-Transformer Attention in Medical Segmentation](#Pre-Transformer-Attention-in-Medical-Segmentation)
  - [Transformer in medical Segmentation](#Transformer-in-medical-Segmentation)
  - [Mamba in medical Segmentation](#Mamba-in-medical-Segmentation)
## Citation

If you find our work useful in your research, please consider citing:
```

```

## List of related papers and code
### Pre-Transformer Attention in Medical Segmentation
- **SW-3D-UNet:** Sun, Liyan and Ma, Wenao and Ding, Xinghao and Huang, Yue and Liang, Dong and Paisley, John.<br />
  "A 3D Spatially Weighted Network for Segmentation of Brain Tissue From MRI" **IEEE Transactions on Medical Imaging (2019)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/8811612/)]

- Bui, Toan Duc and Wang, Li and Chen, Jian and Lin, Weili and Li, Gang and Shen, Dinggang.<br />
  "Multi-task Learning for Neonatal Brain Segmentation Using 3D Dense-Unet with Dense Attention Guided by Geodesic Distance" **MICCAI Workshop (2019)**.
  [[paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7034948/)]

- Noori, Mehrdad and Bahri, Ali and Mohammadi, Karim.<br />
  "Attention-Guided Version of 2D UNet for Automatic Brain Tumor Segmentation" **ICCKE (2019)**.
  [[paper](https://arxiv.org/pdf/2004.02009)]

- Zhou, Chenhong and Ding, Changxing and Wang, Xinchao and Lu, Zhentai and Tao, Dacheng.<br />
  "One-pass Multi-task Networks with Cross-task Guided Attention for Brain Tumor Segmentation" **IEEE Transactions on Image Processing (2020)**.
  [[paper](https://arxiv.org/pdf/1906.01796)]
  [[paper](https://github.com/chenhong-zhou/OM-Net)]

- **UAGAN:** Yuan, Wenguang and Wei, Jia and Wang, Jiabing and Ma, Qianli and Tasdizen, Tolga.<br />
  "Unified Attentional Generative Adversarial Network for Brain Tumor Segmentation From Multimodal Unpaired Images" **MICCAI (2019)**.
  [[paper](https://arxiv.org/pdf/1907.03548)]

- **DCAN:** Xu, Hai and Xie, Hongtao and Liu, Yizhi and Cheng, Chuandong and Niu, Chaoshi and Zhang, Yongdong.<br />
  "Deep Cascaded Attention Network for Multi-task Brain Tumor Segmentation" **MICCAI (2019)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32248-9_47)]

- **AGResU-Net:** Zhang, Jianxin and Jiang, Zongkang and Dong, Jing and Hou, Yaqing and Liu, Bin.<br />
  "Attention Gate ResU-Net for automatic MRI brain tumor segmentation" **IEEE Access (2020)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/09046011.pdf)]

- Akil, Mohamed and Saouli, Rachida and Kachouri, Rostom and others.<br />
  "Fully automatic brain tumor segmentation with deep learning-based selective attention using overlapping patches and multi-class weighted cross-entropy" **Medical image analysis (2020)**.
  [[paper](https://www.sciencedirect.com/science/article/am/pii/S1361841520300578)]
  [[code](https://github.com/MostefaBen)]

- Islam, Mobarakol and Vibashan, VS and Jose, V and Wijethilake, Navodini and Utkarsh, Uppal and Ren, Hongliang.<br />
  "Brain Tumor Segmentation and Survival Prediction Using 3D Attention Unet" **International MICCAI Brainlesion Workshop (2019)**.
  [[paper](https://arxiv.org/pdf/2104.00985)]

- Zhou, Tongxue and Ruan, Su and Guo, Yu and Canu, St{\'e}phane.<br />
  "A Multi-Modality Fusion Network Based on Attention Mechanism for Brain Tumor Segmentation" **ISBI (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9098392)]

- **MASSL:** Chen, Shuai and Bortsova, Gerda and Garc{\'\i}a-Uceda Ju{\'a}rez, Antonio and Tulder, Gijs van and Bruijne, Marleen de.<br />
  "Multi-Task¬†Attention-Based Semi-Supervised Learning for¬†Medical¬†Image¬†Segmentation" **MICCAI (2019)**.
  [[paper](https://arxiv.org/pdf/1907.12303)]

- **MASSL:** Zhou, Chenhong and Chen, Shengcong and Ding, Changxing and Tao, Dacheng.<br />
  "Learning Contextual and Attentive Information for Brain Tumor Segmentation" **International MICCAI brainlesion workshop (2018)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-11726-9_44)]

- **ARU-GD:** Maji, Dhiraj and Sigedar, Prarthana and Singh, Munendra.<br />
  "Attention¬†Res-UNet with Guided Decoder for semantic¬†segmentation¬†of brain tumors" **Biomedical Signal Processing and Control (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1746809421006741)]
  [[code](https://github.com/dhirajmaji7/Attention-Res-UNet-with-Guided-Decoder-for-Semantic-Segmentation-of-Brain-tumors.git)]

- **MIRAU-Net:** AboElenein, Nagwa M and Piao, Songhao and Noor, Alam and Ahmed, Pir Noman.<br />
  "MIRAU-Net: An improved neural network based on U-Net for gliomas¬†segmentation" **Signal Processing: Image Communication (2022)**.
  [[paper](http://www.cister.isep.ipp.pt/docs/mirau_net__an_improved_neural_network_based_on_u_net_for_gliomas_segmentation_/1782/view.pdf)]

- **MIRAU-Net:** Fang, Ying and Huang, He and Yang, Weiji and Xu, Xiaomei and Jiang, Weiwei and Lai, Xiaobo.<br />
  "Nonlocal convolutional block¬†attention¬†module VNet for gliomas automatic¬†segmentation" **International Journal of Imaging Systems and Technology (2022)**.
  [[paper](https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.22639)]

- **AUNet:** Sun, Hui and Li, Cheng and Liu, Boqiang and Liu, Zaiyi and Wang, Meiyun and Zheng, Hairong and Feng, David Dagan and Wang, Shanshan.<br />
  "AUNet:¬†attention-guided dense-upsampling networks for breast mass¬†segmentation¬†in whole mammograms" **Physics in Medicine & Biology (2020)**.
  [[paper](https://arxiv.org/pdf/1810.10151)]

- Lei, Baiying and Huang, Shan and Li, Hang and Li, Ran and Bian, Cheng and Chou, Yi-Hong and Qin, Jing and Zhou, Peng and Gong, Xuehao and Cheng, Jie-Zhi.<br />
  "Self-co-attention¬†neural network for anatomy¬†segmentation¬†in whole breast ultrasound" **Medical image analysis (2020)**.
  [[paper](https://drive.google.com/file/d/1A12NIpaD4_MEpCN5H94tD_UWBhYyr7YX/view)]
  
- **MSGRAP:** Lee, Haeyun and Park, Jinhyoung and Hwang, Jae Youn.<br />
  "Channel¬†attention¬†module with multiscale grid average pooling for breast cancer¬†segmentation¬†in an ultrasound image" **IEEE transactions on ultrasonics, ferroelectrics, and frequency control (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/8988165/)]

- **RDAU-NET:** Zhuang, Zhemin and Li, Nan and Joseph Raj, Alex Noel and Mahesh, Vijayalakshmi GV and Qiu, Shunmin.<br />
  "An RDAU-NET model for lesion segmentation in breast ultrasound images" **IPloS one (2019)**.
  [[paper](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0221535&type=printable)]
 
- Vakanski, Aleksandar and Xian, Min and Freer, Phoebe E.<br />
  "Attention-enriched deep learning model for breast tumor segmentation in ultrasound images" **Ultrasound in medicine & biology (2020)**.
  [[paper](https://arxiv.org/abs/1910.08978)]

- **RCA-IUnet:** Punn, Narinder Singh and Agarwal, Sonali.<br />
  "RCA-IUnet: a residual cross-spatial¬†attention-guided inception U-Net model for tumor¬†segmentation¬†in breast ultrasound imaging" **Machine Vision and Applications (2022)**.
  [[paper](https://arxiv.org/pdf/2108.02508)]

- **K-Net:** Ge, Rongjun and Yang, Guanyu and Chen, Yang and Luo, Limin and Feng, Cheng and Ma, Hong and Ren, Junyi and Li, Shuo.<br />
  "K-Net: Integrate Left Ventricle Segmentation and Direct Quantification of Paired Echo Sequence" **IEEE Transactions on Medical Imaging (2019)**.
  [[paper](http://www.digitalimaginggroup.ca/members/Shuo/K-Net.pdf)]

- **CAB U-Net:** Ding, Xiaofeng and Peng, Yaxin and Shen, Chaomin and Zeng, Tieyong.<br />
  "CAB U-Net: An end-to-end Category Attention Boosting algorithm for segmentation" **Computerized Medical Imaging and Graphics (2020)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0895611120300677)]

- Li, Lei and Weng, Xin and Schnabel, Julia A and Zhuang, Xiahai.<br />
  "Joint left atrial¬†segmentation¬†and scar quantification based on a DNN with spatial encoding and shape¬†attention" **MICCAI (2020)**.
  [[paper](https://arxiv.org/pdf/2006.13011)]

- **PLANet:** Liu, Fei and Wang, Kun and Liu, Dan and Yang, Xin and Tian, Jie.<br />
  "Deep pyramid local¬†attention¬†neural network for cardiac structure¬†segmentation¬†in two-dimensional echocardiography" **Medical Image Analysis (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1361841520302371)]

- Guo, Libao and Lei, Baiying and Chen, Weiling and Du, Jie and Frangi, Alejandro F and Qin, Jing and Zhao, Cheng and Shi, Pengpeng and Xia, Bei and Wang, Tianfu.<br />
  "Dual attention enhancement feature fusion network for segmentation and quantitative analysis of paediatric echocardiography" **Medical Image Analysis (2021)**.
  [[paper](https://eprints.whiterose.ac.uk/178623/1/Dual%20Attention%20Enhancement%20Feature%20Fusion%20Network%20for%20Segmentation%20and%20Quantitative%20Analysis%20of%20Paediatric%20Echocardiography.pdf)]
  [[paper](https://github.com/end-of-the-century/Cardiac)]
  
- Ahn, Shawn S and Ta, Kevinminh and Thorn, Stephanie and Langdon, Jonathan and Sinusas, Albert J and Duncan, James S.<br />
  "Dual attention enhancement feature fusion network for segmentation and quantitative analysis of paediatric echocardiography" **MICCAI (2021)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-87193-2_33)]

- Tong, Qianqian and Li, Caizi and Si, Weixin and Liao, Xiangyun and Tong, Yaliang and Yuan, Zhiyong and Heng, Pheng Ann.<br />
  "RIANet: Recurrent interleaved attention network for cardiac MRI segmentation" **Computers in biology and medicine (2019)**.
  [[paper](https://drive.google.com/file/d/1xQJRSmAm-CNGRzllSstQXsZmVwyI2CCs/view)]

- **HAANet:** Li, Caizi and Tong, Qianqian and Liao, Xiangyun and Si, Weixin and Sun, Yinzi and Wang, Qiong and Heng, Pheng-Ann.<br />
  "Attention Based Hierarchical Aggregation Network for 3D Left Atrial Segmentation" **International Workshop on Statistical Atlases and Computational Models of the Heart (2018)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-12029-0_28)]

- Liu, Jinping and Liu, Hui and Gong, Subo and Tang, Zhaohui and Xie, Yongfang and Yin, Huazhan and Niyoyita, Jean Paul.<br />
  "Automated cardiac segmentation of cross-modal medical images using unsupervised multi-domain adaptation and spatial neural attention structure" **Medical Image Analysis (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S136184152100181X)]

- Wang, Kai-Ni and Yang, Xin and Miao, Juzheng and Li, Lei and Yao, Jing and Zhou, Ping and Xue, Wufeng and Zhou, Guang-Quan and Zhuang, Xiahai and Ni, Dong.<br />
  "AWSnet: An Auto-weighted Supervision¬†Attention¬†Network for Myocardial Scar and Edema¬†Segmentation¬†in Multi-sequence Cardiac Magnetic Resonance Images" **Medical Image Analysis (2022)**.
  [[paper](https://arxiv.org/pdf/2201.05344)]
  [[code](https://github.com/soleilssss/AWSnet/tree/master)]

- Lu, Chenggang and Guo, Zhitao and Yuan, Jinli and Xia, Kewen and Yu, Hengyong.<br />
  "Fine-grained calibrated double-attention¬†convolutional network for left ventricular¬†segmentation" **Physics in Medicine & Biology (2022)**.
  [[paper](https://iopscience.iop.org/article/10.1088/1361-6560/ac5570/meta)]

- Xie, Feng and Huang, Zheng and Shi, Zhengjin and Wang, Tianyu and Song, Guoli and Wang, Bolun and Liu, Zihong.<br />
  "DUDA-Net: a double U-shaped dilated¬†attention¬†network for automatic infection area¬†segmentation¬†in COVID-19 lung CT images" **International Journal of Computer Assisted Radiology and Surgery (2021)**.
  [[paper](https://link.springer.com/content/pdf/10.1007/s11548-021-02418-w.pdf)]

- Chen, Xiaocong and Yao, Lina and Zhang, Yu.<br />
  "Residual Attention U-Net for Automated Multi-Class Segmentation of COVID-19 Chest CT Images" **arXiv (2020)**.
  [[paper](https://arxiv.org/pdf/2004.05645)]

- Zhang, Ju and Yu, Lunduan and Chen, Decheng and Pan, Weidong and Shi, Chao and Niu, Yan and Yao, Xinwei and Xu, Xiaobin and Cheng, Yun.<br />
  "Dense GAN and multi-layer attention based lesion segmentation method for COVID-19 CT images" **Biomedical Signal Processing and Control (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1746809421004985)]

- Karthik, R and Menaka, R and Hariharan, M and Won, Daehan.<br />
  "Contour-enhanced¬†Attention¬†CNN for CT-based COVID-19¬†Segmentation" **Pattern Recognition (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S003132032200019X)]

- Hu, Haigen and Shen, Leizhao and Guan, Qiu and Li, Xiaoxin and Zhou, Qianwei and Ruan, Su.<br />
  "Deep co-supervision and attention fusion strategy for automatic COVID-19 lung infection segmentation on CT images" **Pattern Recognition (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320321006282)]

- **CHS-Net:** Punn, Narinder Singh and Agarwal, Sonali.<br />
  "CHS-Net: A Deep Learning Approach for Hierarchical¬†Segmentation¬†of COVID-19 via CT Images" **Neural Processing Letters (2022)**.
  [[paper](https://link.springer.com/content/pdf/10.1007/s11063-022-10785-x.pdf)]

- **CHS-Net:** Punn, Narinder Singh and Agarwal, Sonali.<br />
  "CHS-Net: A Deep Learning Approach for Hierarchical¬†Segmentation¬†of COVID-19 via CT Images" **Neural Processing Letters (2022)**.
  [[paper](https://link.springer.com/content/pdf/10.1007/s11063-022-10785-x.pdf)]

- Jia, Zijing and Wang, Chaoli and Sun, Zhanquan and Geng, Hongquan and Fu, Hongliang.<br />
  "A New Segmentation Network of Pediatric Renography Based on Attention Mechanism" **Proceedings of 2021 Chinese Intelligent Systems Conference (2022)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-981-16-6320-8_17)]

- **Attention-based V-Net:** Hu, Yucheng and Deng, Han and Zhou, Yang and Chen, Yimin and Hao, Zhou and Yang, Wanqi.<br />
  "Automatic Kidney and Tumor Segmentation with Attention-based V-Net" **University of Minnesota Libraries Publishing (2019)**.
  [[paper](https://core.ac.uk/download/pdf/231905017.pdf)]

- Myronenko, Andriy and Hatamizadeh, Ali.<br />
  "3D Kidneys and Kidney Tumor Semantic Segmentation using Boundary-Aware Networks" **arXiv (2019)**.
  [[paper](https://arxiv.org/pdf/1909.06684)]

- **DGC:** Xuan, Ping and Cui, Hui and Zhang, Hongda and Zhang, Tiangang and Wang, Linlin and Nakaguchi, Toshiya and Duh, Henry BL.<br />
  "Dynamic graph convolutional autoencoder with node-attribute-wise attention for kidney and tumor segmentation from CT volumes" **UKnowledge-Based Systems (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705121006225)]

- **Hyper Vision Net:** Sabarinathan, D and Parisa Beham, M and Mansoor Roomi, SM.<br />
  "Hyper Vision Net: Kidney Tumor Segmentation Using Coordinate Convolutional Layer and Attention Unit" **NCVPRIPG (2019)**.
  [[paper](https://arxiv.org/pdf/1908.03339)]

  Kuang, Haopeng and Yang, Dingkang and Wang, Shunli and Wang, Xiaoying and Zhang, Lihua.<br />
  "Towards Simultaneous Segmentation of Liver Tumors and Intrahepatic Vessels via Cross-attention Mechanism" **ICASSP (2023)**.
  [[paper](https://arxiv.org/pdf/2302.09785)]

- **RA-UNet:** Jin, Qiangguo and Meng, Zhaopeng and Sun, Changming and Cui, Hui and Su, Ran.<br />
  "RA-UNet: A hybrid deep attention-aware network to extract liver and tumor in CT scans" **Frontiers in Bioengineering and Biotechnology (2020)**.
  [[paper](https://www.frontiersin.org/articles/10.3389/fbioe.2020.605132/full)]

- **Attention U-Net++:** Li, Chen and Tan, Yusong and Chen, Wei and Luo, Xin and Gao, Yuanming and Jia, Xiaogang and Wang, Zhiying.<br />
  "Attention unet++: A nested attention-aware u-net for liver ct image segmentation" **ICIP (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9190761/)]

- Haselji{\'c}, Hana and Chatterjee, Soumick and Frysch, Robert and Kulvait, Vojt{\v{e}}ch and Semshchikov, Vladimir and Hensen, Bennet and Wacker, Frank and Br{\"u}sch, Inga and Werncke, Thomas and Speck, Oliver and others.<br />
  "Liver Segmentation using Turbolift Learning for CT and Cone-beam C-arm Perfusion Imaging" **Computers in Biology and Medicine (2023)**.
  [[paper](https://arxiv.org/pdf/2207.10167)]
  [[code](https://github.com/soumickmj/Turbolift)]
  
- Chen, Xueying and Zhang, Rong and Yan, Pingkun.<br />
  "Feature Fusion Encoder Decoder Network for Automatic Liver Lesion Segmentation" **ISBI (2019)**.
  [[paper](https://arxiv.org/pdf/1903.11834)]

- **AHCNet:** Jiang, Huiyan and Shi, Tianyu and Bai, Zhiqi and Huang, Liangliang.<br />
  "AHCNet: An Application of Attention Mechanism and Hybrid Connection for Liver Tumor Segmentation in CT Volumes" **IEEE Access (2019)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/08651448.pdf)]

- **CAAGP:** Zhang, Chi and Lu, Jingben and Yang, Luxi and Li, Chunguo.<br />
  "CAAGP: Rethinking channel attention with adaptive global pooling for liver tumor segmentation" **Computers in Biology and Medicine (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0010482521006697)]
  
- **ResCEAttUnet:** Bi, Rongrong and Ji, Chunlei and Yang, Zhipeng and Qiao, Meixia and Lv, Peiqing and Wang, Haiying.<br />
  "Residual based attention-Unet combing DAC and RMP modules for automatic liver tumor segmentation in CT" **Mathematical Biosciences and Engineering (2022)**.
  [[paper](https://www.aimspress.com/aimspress-data/mbe/2022/5/PDF/mbe-19-05-219.pdf)]
  
- **SAA-Net:** Zhang, Chi and Lu, Jingben and Hua, Qianqian and Li, Chunguo and Wang, Pengwei.<br />
  "SAA-Net: U-shaped network with Scale-Axis-Attention for liver tumor segmentation" **Biomedical Signal Processing and Control (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1746809421010570)]
  
- **MA-Net:** Fan, Tongle and Wang, Guanglei and Li, Yan and Wang, Hongrui.<br />
  "MA-Net: A Multi-Scale Attention Network for Liver and Tumor Segmentation" **IEEE Access (2020)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/8948470/09201310.pdf)]
  
- **LVSNet:** Yan, Qingsen and Wang, Bo and Zhang, Wei and Luo, Chuan and Xu, Wei and Xu, Zhengqing and Zhang, Yanning and Shi, Qinfeng and Zhang, Liang and You, Zheng.<br />
  "Attention-Guided Deep Neural Network With Multi-Scale Feature Fusion for Liver Vessel Segmentation" **IEEE Journal of Biomedical and Health Informatics (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9277536/)]
  
- Qin, Yulei and Zheng, Hao and Gu, Yun and Huang, Xiaolin and Yang, Jie and Wang, Lihui and Zhu, Yue-Min.<br />
  "Learning bronchiole-sensitive airway segmentation CNNs by feature recalibration and attention distillation" **MICCAI (2020)**.
  [[paper](https://hal.science/hal-03435078/file/QinYulei_Miccai2020.pdf)]
  
- Tan, Wenjun and Liu, Pan and Li, Xiaoshuo and Xu, Shaoxun and Chen, Yufei and Yang, Jinzhu.<br />
  "Segmentation of lung airways based on deep learning methods" **IET Image Processing (2022)**.
  [[paper](https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12423)]
  
- **SD-UNet:** Yin, Shuangcai and Deng, Hongmin and Xu, Zelin and Zhu, Qilin and Cheng, Junfeng.<br />
  "SD-UNet: A Novel Segmentation Framework for CT Images of Lung Infections" **Electronics (2022)**.
  [[paper](https://www.mdpi.com/2079-9292/11/1/130)]
  
- **XLSor:** Tang, You-Bao and Tang, Yu-Xing and Xiao, Jing and Summers, Ronald M.<br />
  "XLSor: A Robust and Accurate Lung Segmentor on Chest X-Rays Using Criss-Cross Attention and Customized Radiorealistic Abnormalities Generation" **International Conference on Medical Imaging with Deep Learning (2019)**.
  [[paper](http://proceedings.mlr.press/v102/tang19a/tang19a.pdf)]
  [[code](https://github.com/rsummers11/CADLab/tree/master/Lung_Segmentation_XLSor)]
  
- **Attention U-Net:** Oktay, Ozan and Schlemper, Jo and Folgoc, Loic Le and Lee, Matthew and Heinrich, Mattias and Misawa, Kazunari and Mori, Kensaku and McDonagh, Steven and Hammerla, Nils Y and Kainz, Bernhard and others.<br />
  "Attention U-Net: Learning Where to Look for the Pancreas" **MIDL (2018)**.
  [[paper](https://arxiv.org/abs/1804.03999)]
  [[code]( https://github.com/ozan-oktay/Attention-Gated-Networks)]
 
- **M3Net:** Qu, Taiping and Wang, Xiheng and Fang, Chaowei and Mao, Li and Li, Juan and Li, Ping and Qu, Jinrong and Li, Xiuli and Xue, Huadan and Yu, Yizhou and others.<br />
  "M3Net: A multi-scale multi-view framework for multi-phase pancreas segmentation based on cross-phase non-local attention" **Medical image analysis (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1361841521002772)]

- **PraNet:** Fan, Deng-Ping and Ji, Ge-Peng and Zhou, Tao and Chen, Geng and Fu, Huazhu and Shen, Jianbing and Shao, Ling.<br />
  "PraNet: Parallel Reverse Attention Network for Polyp Segmentation" **MICCAI (2020)**.
  [[paper](https://arxiv.org/pdf/2006.11392)]
  [[code](https://github.com/DengPingFan/PraNet)]
  
- **DDANet:** Tomar, Nikhil Kumar and Jha, Debesh and Ali, Sharib and Johansen, H{\aa}vard D and Johansen, Dag and Riegler, Michael A and Halvorsen, P{\aa}l}.<br />
  "DDANet: Dual decoder attention network for automatic polyp segmentation" **ICPR (2021)**.
  [[paper](https://arxiv.org/pdf/2012.15245)]
  [[code](https://github.com/nikhilroxtomar/DDANet)]
  
- Wei, Jun and Hu, Yiwen and Zhang, Ruimao and Li, Zhen and Zhou, S Kevin and Cui, Shuguang.<br />
  "Shallow attention network for polyp segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/pdf/2108.00882)]
  
- **UACANet:** Kim, Taehun and Lee, Hyemin and Kim, Daijin.<br />
  "UACANet: Uncertainty Augmented Context Attention for Polyp Segmentation" **Proceedings of the 29th ACM International Conference on Multimedia (2021)**.
  [[paper](https://dl.acm.org/doi/pdf/10.1145/3474085.3475375)]
  [[code](https://github.com/plemeri/UACANet)]
  
- **Focus U-Net:** Yeung, Michael and Sala, Evis and Sch{\"o}nlieb, Carola-Bibiane and Rundo, Leonardo.<br />
  "Focus U-Net: A novel dual attention-gated CNN for polyp segmentation during colonoscopy" **Computers in biology and medicine (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0010482521006090)]

- **sECANet:** Yang, Kun and Chang, Shilong and Tian, Zhaoxing and Gao, Cong and Du, Yu and Zhang, Xiongfeng and Liu, Kun and Meng, Jie and Xue, Linyan.<br />
  "Automatic polyp detection and segmentation using shuffle efficient channel attention network" **Alexandria Engineering Journal (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1110016821003148)]
  [[code]()]
  
- Lei, Yang and Dong, Xue and Tian, Zhen and Liu, Yingzi and Tian, Sibo and Wang, Tonghe and Jiang, Xiaojun and Patel, Pretesh and Jani, Ashesh B and Mao, Hui and others.<br />
  "CT Prostate Segmentation Based on Synthetic MRI-aided Deep Attention Fully Convolution Network" **Medical physics (2020)**.
  [[paper](https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.13933)]
  
- Xu, Xuanang and Lian, Chunfeng and Wang, Shuai and Wang, Andrew and Royce, Trevor and Chen, Ronald and Lian, Jun and Shen, Dinggang.<br />
  "Asymmetrical multi-task attention U-net for the segmentation of prostate bed in CT image" **MICCAI (2020)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-59719-1_46)]
  [[code](https://github.com/superxuang/amta-net)]
  
- Wang, Yi and Dou, Haoran and Hu, Xiaowei and Zhu, Lei and Yang, Xin and Xu, Ming and Qin, Jing and Heng, Pheng-Ann and Wang, Tianfu and Ni, Dong.<br />
  "Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound" **IEEE Transactions on Medical Imaging (2019)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/8698868/)]
  [[code](https://github.com/wulalago/DAF3D)]
  
- Liu, Yongkai and Yang, Guang and Mirak, Sohrab Afshari and Hosseiny, Melina and Azadikhah, Afshin and Zhong, Xinran and Reiter, Robert E and Lee, Yeejin and Raman, Steven S and Sung, Kyunghyun}.<br />
  "Automatic Prostate Zonal Segmentation Using Fully Convolutional Network With Feature Pyramid Attention" **IEEE Access (2019)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/8600701/08894451.pdf)]
  [[code](https://github.com/ykl-ucla/prostate_zonal_seg)]
  
- Kearney, Vasant and Chan, Jason W and Wang, Tianqi and Perry, Alan and Yom, Sue S and Solberg, Timothy D.<br />
  "Attention-enabled 3D boosted convolutional neural networks for semantic CT segmentation using deep supervision" **Physics in Medicine & Biology (2019)**.
  [[paper](https://iopscience.iop.org/article/10.1088/1361-6560/ab2818/meta)]

- **HD-Net:** Jia, Haozhe and Song, Yang and Huang, Heng and Cai, Weidong and Xia, Yong.<br />
  "HD-Net: Hybrid Discriminative Network for Prostate Segmentation in MR Images" **MICCAI (2019)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32245-8_13)]

- Li, Jingyuan and Liao, Guanqun and Sun, Wenfang and Sun, Ji and Sheng, Tai and Zhu, Kaibin and von Deneen, Karen M and Zhang, Yi.<br />
  "A 2.5 D semantic segmentation of the pancreas using Attention guided Dual Context embedded U-Net" **Neurocomputing (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0925231222000650)]

- **ProstAttention-Net:** Duran, Audrey and Dussert, Gaspard and Rouvi{\'e}re, Olivier and Jaouen, Tristan and Jodoin, Pierre-Marc and Lartizien, Carole.<br />
  "ProstAttention-Net: a deep attention model for prostate cancer segmentation by aggressiveness in MRI scans" **Medical Image Analysis (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/am/pii/S1361841521003923)]
  
- **CS-Net:** Mou, Lei and Zhao, Yitian and Chen, Li and Cheng, Jun and Gu, Zaiwang and Hao, Huaying and Qi, Hong and Zheng, Yalin and Frangi, Alejandro and Liu, Jiang.<br />
  "CS-Net: Channel and Spatial Attention Network for Curvilinear Structure Segmentation" **MICCAI (2019)**.
  [[paper](https://eprints.whiterose.ac.uk/160601/1/)]
  
- **AG-Net:** Zhang, Shihao and Fu, Huazhu and Yan, Yuguang and Zhang, Yubing and Wu, Qingyao and Yang, Ming and Tan, Mingkui and Xu, Yanwu.<br />
  "Attention Guided Network for Retinal Image Segmentation" **MICCAI (2019)**.
  [[paper](https://arxiv.org/pdf/1907.12930)]
  [[code](https://github.com/HzFu/AGNet)]
  
- Li, Xiang and Jiang, Yuchen and Li, Minglei and Yin, Shen.<br />
  "Lightweight Attention Convolutional Neural Network for Retinal Vessel Image Segmentation" **IEEE Transactions on Industrial Informatics (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9091247/)]
  
- **SAT-Net:** Tong, Huilin and Fang, Zhijun and Wei, Ziran and Cai, Qingping and Gao, Yongbin.<br />
  "SAT-Net: a side attention network for retinal image segmentation" **Applied Intelligence (2021)**.
  [[paper](https://link.springer.com/article/10.1007/s10489-020-01966-z)]
  
- **DEU-Net:** Wang, Bo and Qiu, Shuang and He, Huiguang.<br />
  "Dual Encoding U-Net for Retinal Vessel Segmentation" **MICCAI (2019)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32239-7_10)]
  
- **CAR-UNet:** Guo, Changlu and Szemenyei, Marton and Hu, Yangtao and Wang, Wenle and Zhou, Wei and Yi, Yugen.<br />
  "Channel attention residual u-net for retinal vessel segmentation" **ICASSP (2021)**.
  [[paper](https://arxiv.org/pdf/2004.03702)]
  [[code](https://github.com/clguo/CAR-UNet)]
  
- **CSAU:** Li, Ruirui and Li, Mingming and Li, Jiacheng and Zhou, Yating.<br />
  "Connection Sensitive Attention U-NET for Accurate Retinal Vessel Segmentation" **arXiv (2019)**.
  [[paper](https://arxiv.org/pdf/1903.05558)]
  
- Luo, Zhongming and Zhang, Yu and Zhou, Lei and Zhang, Binge and Luo, Jianan and Wu, Haibin.<br />
  "Micro-Vessel Image Segmentation Based on the AD-UNet Model" **IEEE Access (2019)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/8600701/08859307.pdf)]  

- **Sa-unet:** Guo, Changlu and Szemenyei, M{\'a}rton and Yi, Yugen and Wang, Wenle and Chen, Buer and Fan, Changqi.<br />
  "Sa-unet: Spatial attention u-net for retinal vessel segmentation" **ICPR (2021)**.
  [[paper](https://arxiv.org/pdf/2004.03696)]
  [[code](https://github.com/clguo/SA-UNet)]
  
- **RSAN:** Guo, Changlu and Szemenyei, M{\'a}rton and Yi, Yugen and Zhou, Wei and Bian, Haodong.<br />
  "Residual spatial attention network for retinal vessel segmentation" **ICONIP (2020)**.
  [[paper](https://arxiv.org/pdf/2009.08829)]
  [[code](https://github.com/clguo/RSAN)]

- **FANet:** Li, Kaiqi and Qi, Xingqun and Luo, Yiwen and Yao, Zeyi and Zhou, Xiaoguang and Sun, Muyi.<br />
  "Accurate retinal vessel segmentation in color fundus images via fully attention-based networks" **IEEE Journal of Biomedical and Health Informatics (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9210783/)]
  [[code]()]
  
- Jiang, Yun and Yao, Huixia and Ma, Zeqi and Zhang, Jingyao.<br />
  "Bi-SANet‚ÄîBilateral Network with Scale Attention for Retinal Vessel Segmentation" **Symmetry (2021)**.
  [[paper](https://www.mdpi.com/2073-8994/13/10/1820/pdf)]
  
- Wang, Dongyi and Haytham, Ayman and Pottenburgh, Jessica and Saeedi, Osamah and Tao, Yang.<br />
  "Hard attention net for automatic retinal vessel segmentation" **IEEE Journal of Biomedical and Health Informatics (2020)**.
  [[paper](https://www.researchgate.net/profile/Dongyi-Wang-2/publication/342248007_Hard_Attention_Net_for_Automatic_Retinal_Vessel_Segmentation/links/5eeac2aa458515814a674d17/Hard-Attention-Net-for-Automatic-Retinal-Vessel-Segmentation.pdf)]

- **DA-U-Net:** Wu, Cong and Zou, Yixuan and Zhan, Jinhao.<br />
  "DA-U-Net: Densely Connected Convolutional Networks and Decoder with Attention Gate for Retinal Vessel Segmentation" **IOP Conference Series: Materials Science and Engineering (2019)**.
  [[paper](https://iopscience.iop.org/article/10.1088/1757-899X/533/1/012053/pdf)]
  
- **S-UNet:** Hu, Jingfei and Wang, Hua and Gao, Shengbo and Bao, Mingkun and Liu, Tao and Wang, Yaxing and Zhang, Jicong.<br />
  "S-UNet: A Bridge-Style U-Net Framework With a Saliency Mechanism for Retinal Vessel Segmentation" **IEEE Access (2019)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/08842560.pdf)]  

- Lyu, Chengzhi and Hu, Guoqing and Wang, Dan.<br />
  "Attention to fine-grained information: hierarchical multi-scale network for retinal vessel segmentation" **The Visual Computer (2020)**.
  [[paper](https://link.springer.com/article/10.1007/s00371-020-02018-w)]
  
- **AA-UNet:** Lv, Yan and Ma, Hui and Li, Jianian and Liu, Shuangcai.<br />
  "Attention guided U-Net with atrous convolution for accurate retinal vessels segmentation" **IEEE Access (2020)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/08999616.pdf)]
  
- Jiang, Yun and Yao, Huixia and Wu, Chao and Liu, Wenhuan.<br />
  "A multi-scale residual attention network for retinal vessel segmentation" **Symmetry (2020)**.
  [[paper](https://www.mdpi.com/2073-8994/13/1/24/pdf)]
  
- **BSEResU-Net:** Li, Di and Rahardja, Susanto.<br />
  "BSEResU-Net: An attention-based before-activation residual U-Net for retinal vessel segmentation" **Computer Methods and Programs in Biomedicine (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0169260721001450)]  

- Wu, Cong-Zhong and Sun, Jun and Wang, Jing and Xu, Liang-Feng and Zhan, Shu.<br />
  "Encoding-decoding network with pyramid self-attention module for retinal vessel segmentation" **International Journal of Automation and Computing (2021)**.
  [[paper](https://www.mi-research.net/en/article/pdf/preview/10.1007/s11633-020-1277-0.pdf)]
  
- **AR-SA U-Net:** Wang, Huadeng and Xu, Guang and Pan, Xipeng and Liu, Zhenbing and Tang, Ningning and Lan, Rushi and Luo, Xiaonan.<br />
  "Attention-inception-based U-Net for retinal vessel segmentation with advanced residual" **Computers & Electrical Engineering (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0045790621005929)]  

- Liu, Congjun and Gu, Penghui and Xiao, Zhiyong.<br />
  "Multiscale U-Net with Spatial Positional Attention for Retinal Vessel Segmentation" **Journal of Healthcare Engineering (2022)**.
  [[paper](https://www.hindawi.com/journals/jhe/2022/5188362/)]
  
- **DCU-net:** Yang, Xin and Li, Zhiqiang and Guo, Yingqing and Zhou, Dake.<br />
  "DCU-net: a deformable convolutional neural network based on cascade U-net for retinal vessel segmentation" **Multimedia Tools and Applications (2022)**.
  [[paper](https://link.springer.com/article/10.1007/s11042-022-12418-w)]
  
- **JointRCNN:** Jiang, Yuming and Duan, Lixin and Cheng, Jun and Gu, Zaiwang and Xia, Hu and Fu, Huazhu and Li, Changsheng and Liu, Jiang.<br />
  "JointRCNN: A Region-Based Convolutional Neural Network for Optic Disc and Cup Segmentation" **IEEE Transactions on Biomedical Engineering (2019)**.
  [[paper](https://www.researchgate.net/profile/Huazhu-Fu/publication/332659142_JointRCNN_A_Region-based_Convolutional_Neural_Network_for_Optic_Disc_and_Cup_Segmentation/links/5dc1597da6fdcc2128056593/JointRCNN-A-Region-based-Convolutional-Neural-Network-for-Optic-Disc-and-Cup-Segmentation.pdf)]
  
- **ATT-UNet:** Lian, Sheng and Luo, Zhiming and Zhong, Zhun and Lin, Xiang and Su, Songzhi and Li, Shaozi.<br />
  "Attention guided U-Net for accurate iris segmentation" **Journal of Visual Communication and Image Representation (2018)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1047320318302372)]
  
- Bhatkalkar, Bhargav J and Reddy, Dheeraj R and Prabhu, Srikanth and Bhandary, Sulatha V.<br />
  "Improving the performance of convolutional neural network for the segmentation of optic disc in fundus images using attention gates and conditional random fields" **IEEE Access (2020)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/08986563.pdf)]
  
- **ADAM:** Wu, Huisi and Pan, Junquan and Li, Zhuoying and Wen, Zhenkun and Qin, Jing.<br />
  "Automated Skin Lesion Segmentation Via an Adaptive Dual Attention Module" **IEEE Transactions on Medical Imaging (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9207942/)]
  [[code]()]

- **Att-DenseUnet:** Wei, Zenghui and Song, Hong and Chen, Lei and Li, Qiang and Han, Guanghui.<br />
  "Attention-Based DenseUnet Network With Adversarial Training for Skin Lesion Segmentation" **IEEE Access (2019)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/8600701/08835031.pdf)]
  
- **ASCU-Net:** Tong, Xiaozhong and Wei, Junyu and Sun, Bei and Su, Shaojing and Zuo, Zhen and Wu, Peng.<br />
  "ASCU-Net: Attention Gate, Spatial and Channel Attention U-Net for Skin Lesion Segmentation" **Diagnostics (2021)**.
  [[paper](https://www.mdpi.com/2075-4418/11/3/501)]
  
- Ren, Yuan and Yu, Long and Tian, Shengwei and Cheng, Junlong and Guo, Zhiqi and Zhang, Yanhan.<br />
  "Serial attention network for skin lesion segmentation" **Journal of Ambient Intelligence and Humanized Computing (2022)**.
  [[paper](https://link.springer.com/article/10.1007/s12652-021-02933-3)]
  
- Arora, Ridhi and Raman, Balasubramanian and Nayyar, Kritagya and Awasthi, Ruchi.<br />
  "Automated skin lesion segmentation using attention-based deep convolutional neural network" **Biomedical Signal Processing and Control (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1746809420304663)]
  
- Wang, Yu and Wang, Shengsheng.<br />
  "Skin lesion segmentation with attention-based SC-Conv U-Net and feature map distortion" **Signal, Image and Video Processing (2022)**.
  [[paper](https://link.springer.com/article/10.1007/s11760-021-02100-3)]
  
- **CA-Net:** Gu, Ran and Wang, Guotai and Song, Tao and Huang, Rui and Aertsen, Michael and Deprest, Jan and Ourselin, S{\'e}bastien and Vercauteren, Tom and Zhang, Shaoting.<br />
  "CA-Net: Comprehensive Attention Convolutional Neural Networks for Explainable Medical Image Segmentation" **IEEE Transactions on Medical Imaging (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9246575/)]
  [[code](https://github.com/HiLab-git/CA-Net)]

- **RASNet:** Ni, Zhen-Liang and Bian, Gui-Bin and Xie, Xiao-Liang and Hou, Zeng-Guang and Zhou, Xiao-Hu and Zhou, Yan-Jie.<br />
  "RASNet: Segmentation for Tracking Surgical Instruments in Surgical Videos Using Refined Attention Segmentation Network" **EMBC (2019)**.
  [[paper](https://arxiv.org/pdf/1905.08663)]
  
- **RAUNet:** Ni, Zhen-Liang and Bian, Gui-Bin and Zhou, Xiao-Hu and Hou, Zeng-Guang and Xie, Xiao-Liang and Wang, Chen and Zhou, Yan-Jie and Li, Rui-Qi and Li, Zhen.<br />
  "RAUNet: Residual Attention U-Net for Semantic Segmentation of Cataract Surgical Instruments" **ICONIP (2019)**.
  [[paper](https://arxiv.org/pdf/1909.10360)]
  
- Jin, Yueming and Cheng, Keyun and Dou, Qi and Heng, Pheng-Ann.<br />
  "Incorporating Temporal Prior from Motion Flow for Instrument Segmentation in Minimally Invasive Surgery Video" **MICCAI (2019)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32254-0_49)]

- **SurgiNet:** Ni, Zhen-Liang and Zhou, Xiao-Hu and Wang, Guan-An and Yue, Wen-Qian and Li, Zhen and Bian, Gui-Bin and Hou, Zeng-Guang.<br />
  "SurgiNet: Pyramid Attention Aggregation and Class-wise Self-Distillation for Surgical Instrument Segmentation" **Medical Image Analysis (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1361841521003558)]
  
- **HDA-ResUNet:** Wang, Zekun and Zou, Yanni and Liu, Peter X.<br />
  "Hybrid dilation and attention residual U-Net for medical image segmentation" **Computers in Biology and Medicine (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0010482521002432)]
  
- **Attention Gated Networks:** Schlemper, Jo and Oktay, Ozan and Schaap, Michiel and Heinrich, Mattias and Kainz, Bernhard and Glocker, Ben and Rueckert, Daniel.<br />
  "Attention Gated Networks: Learning to Leverage Salient Regions in Medical Images" **Medical image analysis (2019)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S1361841518306133)]
  [[code](https://www.github.com/ozan-oktay/Attention-Gated-Networks)]

- **ANU-Net:** Li, Chen and Tan, Yusong and Chen, Wei and Luo, Xin and He, Yulin and Gao, Yuanming and Li, Fei.<br />
  "ANU-Net: Attention-based nested U-Net to exploit full resolution features for medical image segmentation" **Computers & Graphics (2020)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0097849320300546)]
  
- **MSDN:** Wang, Duo and Li, Ming and Ben-Shlomo, Nir and Corrales, C Eduardo and Cheng, Yu and Zhang, Tao and Jayender, Jagadeesan.<br />
  "Mixed-Supervised Dual-Network for Medical Image Segmentation" **MICCAI (2020)**.
  [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32245-8_22)]
  
- **AEC-net:** Wang, Jingyi and Zhao, Xu and Ning, Qingtian and Qian, Dahong.<br />
  "AEC-net: attention and edge constraint network for medical image segmentation" **EMBC (2020)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9176670/)]
  
- **CaraNet:** Lou, Ange and Guan, Shuyue and Loew, Murray.<br />
  "CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects" **Journal of Medical Imaging (2023)**.
  [[paper](https://arxiv.org/pdf/2108.07368)]
  [[code](https://github.com/AngeLouCN/CaraNet)]
  
- Yang, Jin and Qiu, Kai.<br />
  "An improved segmentation algorithm of CT image based on U-Net network and attention mechanism" **Multimedia Tools and Applications (2021)**.
  [[paper](https://link.springer.com/article/10.1007/s11042-021-10841-z)]
  
- Xu, Lu and Gao, Shengbo and Shi, Lijuan and Wei, Boxuan and Liu, Xiaowei and Zhang, Jicong and He, Yihua.<br />
  "Exploiting Vector Attention and Context Prior for Ultrasound Image Segmentation" **Neurocomputing (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0925231221007864)]
  
- **MC-Net:** Xia, Haiying and Ma, Mingjun and Li, Haisheng and Song, Shuxiang.<br />
  "MC-Net: multi-scale context-attention network for medical CT image segmentation" **Applied Intelligence (2022)**.
  [[paper](https://link.springer.com/article/10.1007/s10489-021-02506-z)]
  
- **DCACNet:** Lu, Hongchun and Tian, Shengwei and Yu, Long and Liu, Lu and Cheng, Junlong and Wu, Weidong and Kang, Xiaojing and Zhang, Dezhi.<br />
  "DCACNet: Dual context aggregation and attention-guided cross deconvolution network for medical image segmentation" **Computer Methods and Programs in Biomedicine (2022)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0169260721006404)]
  [[code]()]
  
- **:** Cheng, Zhiming and Qu, Aiping and He, Xiaofeng.<br />
  "Contour-aware semantic segmentation network with spatial attention mechanism for medical image" **The Visual Computer (2022)**.
  [[paper](https://link.springer.com/content/pdf/10.1007/s00371-021-02075-9.pdf)]
  

- Azad, Reza and Heidari, Moein and Wu, Yuli and Merhof, Dorit.<br />
  "Contextual attention network: Transformer meets u-net" **International Workshop on Machine Learning in Medical Imaging (2022)**.
  [[paper](https://arxiv.org/pdf/2203.01932)]
  [[code]()]

- Zhang, Mo and Dong, Bin and Li, Quanzheng.<br />
  "JOINT ATTENTION FOR MEDICAL IMAGE SEGMENTATION" **ISBI (2022)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.pdf)]
  
- **CASCADE:** Rahman, Md Mostafijur and Marculescu, Radu.<br />
  "Medical Image Segmentation via Cascaded Attention Decoding" **Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (2023)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.pdf)]
  
- **AFTer-UNet:** Yan, Xiangyi and Tang, Hao and Sun, Shanlin and Ma, Haoyu and Kong, Deying and Xie, Xiaohui.<br />
  "After-unet: Axial fusion transformer unet for medical image segmentation" **Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (2022)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2022/papers/Yan_AFTer-UNet_Axial_Fusion_Transformer_UNet_for_Medical_Image_Segmentation_WACV_2022_paper.pdf)]
  
- **DAR-UNet:** Yao, Kai and Su, Zixian and Huang, Kaizhu and Yang, Xi and Sun, Jie and Hussain, Amir and Coenen, Frans.<br />
  "A novel 3D unsupervised domain adaptation framework for cross-modality medical image segmentation" **IEEE JBHI (2022)**.
  [[paper](https://napier-repository.worktribe.com/preview/2885434/IEEE_JBHI.pdf)]
  [[code](https://github.com/Kaiseem/DAR-UNet)]
  
- Sinha, Ashish and Dolz, Jose.<br />
  "Multi-Scale Self-Guided Attention for Medical Image Segmentation" **IEEE journal of biomedical and health informatics (2020)**.
  [[paper](https://arxiv.org/pdf/1906.02849)]
  [[code](https://github.com/sinAshish/Multi-Scale-Attention)]
  
- An, Feng-Ping and Liu, Jun-e.<br />
  "Medical image segmentation algorithm based on multilayer boundary perception-self attention deep learning model" **Multimedia Tools and Applications (2021)**.
  [[paper](https://link.springer.com/article/10.1007/s11042-021-10515-w)]
  
- Mostayed, Ahmed and Wee, William G and Zhou, Xuefu.<br />
  "Content-Adaptive U-Net Architecture for Medical Image Segmentation" **CSCI (2019)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9070842/)]
  
- **FCANet:** Cheng, Junlong and Tian, Shengwei and Yu, Long and Lu, Hongchun and Lv, Xiaoyi.<br />
  "Fully convolutional attention network for biomedical image segmentation" **Artificial Intelligence in Medicine (2020)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0933365720302220)]
  [[code](https://github.com/luhongchun/FCANet)]
  
- **SA-Net:** Hu, Jingfei and Wang, Hua and Wang, Jie and Wang, Yunqi and He, Fang and Zhang, Jicong.<br />
  "SA-Net: A scale-attention network for medical image segmentation" **PloS one (2021)**.
  [[paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0247388)]
  
- **MA-Unet:** Cai, Yutong and Wang, Yong.<br />
  "MA-Unet: An improved version of Unet based on multi-scale and attention mechanism for medical image segmentation" **ECNCT (2022)**.
  [[paper](https://arxiv.org/pdf/2012.10952)]
  [[code]()]
  
- Fang, Wenhao and Han, Xian-hua.<br />
  "Spatial and Channel Attention Modulated Network for Medical Image Segmentation" **Proceedings of the Asian Conference on Computer Vision (2020)**.
  [[paper](https://openaccess.thecvf.com/content/ACCV2020W/MLCSA/papers/Fang_Spatial_and_Channel_Attention_Modulated_Network_for_Medical_Image_Segmentation_ACCVW_2020_paper.pdf)]  

- Qin, Yao and Kamnitsas, Konstantinos and Ancha, Siddharth and Nanavati, Jay and Cottrell, Garrison and Criminisi, Antonio and Nori, Aditya.<br />
  "Autofocus Layer for Semantic Segmentation" **MICCAI (2018)**.
  [[paper](https://arxiv.org/pdf/1805.08403)]
  [[code](https://github.com/yaq007/Autofocus-Layer)]
  
- **RefineU-Net:** Lin, Dongyun and Li, Yiqun and Nwe, Tin Lay and Dong, Sheng and Oo, Zaw Min.<br />
  "RefineU-Net: Improved U-Net with Progressive Global Feedbacks and Residual Attention Guided Local Refinement for Medical Image Segmentation" **Pattern Recognition Letters (2022)**.
  [[paper](https://oar.a-star.edu.sg/storage/5/5g2z7jorxg/refineu-net-prl-unmarked.pdf)]
  
- **TA-Net:** Li, Yang and Yang, Jun and Ni, Jiajia and Elazab, Ahmed and Wu, Jianhuang.<br />
  "TA-Net: Triple attention network for medical image segmentation" **Computers in Biology and Medicine (2021)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0010482521006302)]
  
- **SCA-Net:** Shan, Tong and Yan, Jiayong.<br />
  "SCA-Net: A Spatial and Channel Attention Network for Medical Image Segmentation" **IEEE Access (2021)**.
  [[paper](https://ieeexplore.ieee.org/abstract/document/9634020/)]
  
- **R2AU-Net:** Zuo, Qiang and Chen, Songyu and Wang, Zhifang.<br />
  "R2AU-Net: Attention Recurrent Residual Convolutional Neural Network for Multimodal Medical Image Segmentation" **Security and Communication Networks (2021)**.
  [[paper](https://www.hindawi.com/journals/scn/2021/6625688/)]
  
- **HANet:** Ding, Fei and Yang, Gang and Wu, Jun and Ding, Dayong and Xv, Jie and Cheng, Gangwei and Li, Xirong.<br />
  "High-Order Attention Networks for Medical Image Segmentation" **MICCAI (2020)**.
  [[paper](https://www.researchgate.net/profile/Gang-Yang-21/publication/346015624_High-Order_Attention_Networks_for_Medical_Image_Segmentation/links/6036408392851c4ed591867e/High-Order-Attention-Networks-for-Medical-Image-Segmentation.pdf)]
  
- **TSMAN:** Min, Shaobo and Chen, Xuejin and Zha, Zheng-Jun and Wu, Feng and Zhang, Yongdong.<br />
  "A Two-Stream Mutual Attention Network for Semi-Supervised Biomedical Segmentation with Noisy Labels" **AAAI (2019)**.
  [[paper](https://aaai.org/ojs/index.php/AAAI/article/view/4381)]
  
- **Et-net:** Zhang, Zhijie and Fu, Huazhu and Dai, Hang and Shen, Jianbing and Pang, Yanwei and Shao, Ling.<br />
  "Et-net: A generic edge-attention guidance network for medical image segmentation" **MICCAI (2019)**.
  [[paper](https://arxiv.org/pdf/1907.10936)]
  [[code](https://github.com/ZzzJzzZ/ETNet)]
  
- Ding, Fei and Yang, Gang and Liu, Jinlu and Wu, Jun and Ding, Dayong and Xv, Jie and Cheng, Gangwei and Li, Xirong.<br />
  "Hierarchical Attention Networks for Medical Image Segmentation" **arXiv (2019)**.
  [[paper](https://arxiv.org/pdf/1911.08777)]
  
- **Focusnet:** Kaul, Chaitanya and Manandhar, Suresh and Pears, Nick.<br />
  "Focusnet: An Attention-Based Fully Convolutional Network for Medical Image Segmentation" **ISBI (2019)**.
  [[paper](https://arxiv.org/pdf/1902.03091)]
  
- Wang, Guotai and Shapey, Jonathan and Li, Wenqi and Dorent, Reuben and Dimitriadis, Alexis and Bisdas, Sotirios and Paddick, Ian and Bradford, Robert and Zhang, Shaoting and Ourselin, S{\'e}bastien and others.<br />
  "Automatic Segmentation of Vestibular Schwannoma from T2-Weighted MRI by Deep Spatial Attention with Hardness-Weighted Loss" **MICCAI (2019)**.
  [[paper](https://arxiv.org/pdf/1906.03906)]
  
- **DAT++:** Xia, Zhuofan and Pan, Xuran and Song, Shiji and Li, Li Erran and Huang, Gao.<br />
  "DAT++: Spatially Dynamic Vision Transformer with Deformable Attention" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2309.01430)]
  [[code](https://github.com/LeapLabTHU/DAT)]
  
- **AgileFormer:** Qiu, Peijie and Yang, Jin and Kumar, Sayantan and Ghosh, Soumyendu Sekhar and Sotiras, Aristeidis.<br />
  "AgileFormer: Spatially Agile Transformer UNet for Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.00122)]
  [[code](https://github.com/sotiraslab/AgileFormer)]
  
- **Attresdu-net:** Khan, Akib Mohammed and Ashrafee, Alif and Khan, Fahim Shahriar and Hasan, Md Bakhtiar and Kabir, Md Hasanul.<br />
  "Attresdu-net: Medical image segmentation using attention-based residual double u-net" **IJCNN (2023)**.
  [[paper](https://arxiv.org/pdf/2306.14255)]
  [[code](https://github.com/fkhan98/Medical-Image-Segmentation-with-Attention-based-Residual-Double-U-Net)]
  
- **BAAF:** Chen, Gongping and Zhao, Lei and Yin, Xiaotao and Cui, Liang and Zhang, Jianxun and Dai, Yu.<br />
  "BAAF: A Benchmark Attention Adaptive Framework for Medical Ultrasound Image Segmentation Tasks" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.00919)]
  [[code](https://github.com/CGPxy/BAAF)]
  
- **CPCA:** Huang, Hejun and Chen, Zuguo and Zou, Ying and Lu, Ming and Chen, Chaoyang.<br />
  "Channel prior convolutional attention for medical image segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2306.05196)]
  [[code](https://github.com/Cuthbert-Huang/CPCANet)]
  
- **MCANet:** Shao, Hao and Zeng, Quansheng and Hou, Qibin and Yang, Jufeng.<br />
  "MCANet: Medical Image Segmentation with Multi-Scale Cross-Axis Attention" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2312.08866)]
  [[code](https://github.com/haoshao-nku/medical_seg.git)]
  
- **DCA:** Ates, Gorkem Can and Mohan, Prasoon and Celik, Emrah.<br />
  "Dual cross-attention for medical image segmentation" **Engineering Applications of Artificial Intelligence (2023)**.
  [[paper](https://arxiv.org/pdf/2303.17696)]
  [[code](https://github.com/gorkemcanates/Dual-Cross-Attention)]


### Transformer in medical Segmentation
- **Cell-DETR:** Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz.<br />
  "Attention-based transformers for instance segmentation of cells in microstructures" **IEEE BIBM (2020)**.
  [[paper](https://arxiv.org/pdf/2102.11650)]
  [[code](https://git.rwth-aachen.de/bcs/projects/cell-detr.git)]
  
- **TransUNet:** Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L and Zhou, Yuyin.<br />
  "TransUNet:¬†Transformers¬†Make Strong Encoders for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2102.04306)]
  [[code](https://github.com/Beckschen/TransUNet)]

- Karimi, Davood and Vasylechko, Serge Didenko and Gholipour, Ali.<br />
  "Convolution-free medical image segmentation using transformers" **MICCAI  (2021)**.
  [[paper](https://arxiv.org/abs/2102.13645)]
  [[code](https://github.com/Beckschen/TransUNet)]

- **CoTr:** Xie, Yutong and Zhang, Jianpeng and Shen, Chunhua and Xia, Yong.<br />
  "CoTr: Efficiently Bridging CNN and Transformer for 3D Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2103.03024)]
  [[code](https://github.com/YtongXie/CoTr)]

- **SpecTr:** Yun, Boxiang and Wang, Yan and Chen, Jieneng and Wang, Huiyu and Shen, Wei and Li, Qingli.<br />
  "SpecTr: Spectral¬†Transformer¬†for Hyperspectral Pathology Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2103.03604)]
  [[code](https://github.com/hfut-xc-yun/SpecTr)]

- **Medical¬†Transformer:** Jun, Eunji and Jeong, Seungwoo and Heo, Da-Woon and Suk, Heung-Il.<br />
  "Medical¬†Transformer: Universal Brain Encoder for 3D MRI Analysis" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2104.13633)]
  [[code](https://github.com/hfut-xc-yun/SpecTr)]

- **Swin-Unet:** Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning.<br />
  "Swin-Unet: Unet-like Pure¬†Transformer¬†for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2105.05537)]
  [[code](https://github.com/HuCaoFighting/Swin-Unet)]

- **Segtran:** Li, Shaohua and Sui, Xiuchao and Luo, Xiangde and Xu, Xinxing and Liu, Yong and Goh, Rick.<br />
  "Medical Image Segmentation Using Squeeze-and-Expansion¬†Transformers" **IJCAI (2021)**.
  [[paper](https://arxiv.org/abs/2105.09511)]
  [[code](https://github.com/askerlee/segtran)]

- **TransBTS:** Wenxuan, Wang and Chen, Chen and Meng, Ding and Hong, Yu and Sen, Zha and Jiangyun, Li.<br />
  "TransBTS: Multimodal Brain Tumor Segmentation Using¬†Transformer" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2103.04430)]
  [[code](https://github.com/Wenxuan-1119/TransBTS)]

- **MCTrans:** Ji, Yuanfeng and Zhang, Ruimao and Wang, Huijie and Li, Zhen and Wu, Lingyun and Zhang, Shaoting and Luo, Ping.<br />
  "Multi-Compound¬†Transformer¬†for Accurate Biomedical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2106.14385)]
  [[code](https://github.com/JiYuanFeng/MCTrans)

- **MedT:** Valanarasu, Jeya Maria Jose and Oza, Poojan and Hacihaliloglu, Ilker and Patel, Vishal M.<br />
  "Medical¬†Transformer: Gated Axial-Attention for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2102.10662)]
  [[code](https://github.com/jeya-maria-jose/Medical-Transformer)]

- **TransFuse:** Zhang, Yundong and Liu, Huiye and Hu, Qiang.<br />
  "TransFuse: Fusing¬†Transformers¬†and CNNs for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2102.08005)]

- **TransClaw U-Net:** Yao, Chang and Hu, Menghan and Li, Qingli and Zhai, Guangtao and Zhang, Xiao-Ping.<br />
  "TransClaw U-Net: Claw U-Net with¬†Transformers¬†for Medical Image Segmentation" **ICICSP (2022)**.
  [[paper](https://arxiv.org/abs/2107.05188)]

- **TransAttUnet:** Chen, Bingzhi and Liu, Yishu and Zhang, Zheng and Lu, Guangming and Kong, Adams Wai Kin.<br />
  "TransAttUnet: Multi-level Attention-guided U-Net with¬†Transformer¬†for Medical Image Segmentation" **TETCI (2023)**.
  [[paper](https://arxiv.org/abs/2107.05274)]
  [[code](https://github.com/YishuLiu/TransAttUnet)]

- **LeViT-UNet:** Xu, Guoping and Zhang, Xuan and He, Xinwei and Wu, Xinglong.<br />
  "LeViT-UNet: Make Faster Encoders with¬†Transformer¬†for Medical Image Segmentation" **PRCV (2023)**.
  [[paper](https://arxiv.org/abs/2107.08623)]
  [[code](https://github.com/apple1986/LeViT_UNet)]

- **Polyp-PVT:** Dong, Bo and Wang, Wenhai and Fan, Deng-Ping and Li, Jinpeng and Fu, Huazhu and Shao, Ling.<br />
  "Polyp-PVT: Polyp Segmentation with Pyramid Vision¬†Transformers" **CAAI AIR (2023)**.
  [[paper](https://arxiv.org/abs/2108.06932)]
  [[code](https://github.com/DengPingFan/Polyp-PVT)]

- **PMTrans:** Zhang, Zhuangzhuang and Zhang, Weixiong.<br />
  "Pyramid Medical¬†Transformer¬†for Medical Image Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2104.14702)]

- **MISSFormer:** Huang, Xiaohong and Deng, Zhifang and Li, Dandan and Yuan, Xueguang.<br />
  "MISSFormer: An Effective Medical Image Segmentation¬†Transformer" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.07162)]
  [[code](https://github.com/ZhifangDeng/MISSFormer)]

- **TUnet:** Sha, Youyang and Zhang, Yonghong and Ji, Xuquan and Hu, Lei.<br />
  "Transformer-Unet: Raw Image Processing with Unet" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.08417)]

- **BiTr-Unet:** Jia, Qiran and Shu, Hai.<br />
  "BiTr-Unet: a CNN-Transformer¬†Combined Network for MRI Brain Tumor Segmentation" **International MICCAI Brainlesion Workshop (2021)**.
  [[paper](https://arxiv.org/abs/2109.12271)]
  [[code](https://github.com/JustaTinyDot/BiTr-Unet)]

- **UTNet:** Gao, Yunhe and Zhou, Mu and Metaxas, Dimitris N.<br />
  "UTNet: A Hybrid¬†Transformer¬†Architecture for Medical Image Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2107.00781)]
  [[code](https://github.com/yhygao/UTNet)]

- **GT U-Net:** Li, Yunxiang and Wang, Shuai and Wang, Jun and Zeng, Guodong and Liu, Wenjun and Zhang, Qianni and Jin, Qun and Wang, Yaqi.<br />
  "GT U-Net: A U-Net Like Group¬†Transformer¬†Network for Tooth Root Segmentation" **International Workshop on MIMI (2021)**.
  [[paper](https://arxiv.org/abs/2109.14813)]
  [[code](https://github.com/Kent0n-Li/GT-U-Net)]

- **nnFormer:** Zhou, Hong-Yu and Guo, Jiansen and Zhang, Yinghao and Yu, Lequan and Wang, Liansheng and Yu, Yizhou.<br />
  "nnFormer: Interleaved¬†Transformer¬†for Volumetric Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2109.03201)]
  [[code](https://git.io/JSf3i)]

- Pandey, Deepanshu and Gupta, Pradyumna and Bhattacharya, Sumit and Sinha, Aman and Agarwal, Rohit.<br />
  "Transformer¬†Assisted Convolutional Network for Cell Instance Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.02270)]
  [[code](https://github.com/dsciitism/SegPC-2021)]

- **BAT:** Wang, Jiacheng and Wei, Lan and Wang, Liansheng and Zhou, Qichao and Zhu, Lei and Qin, Jing.<br />
  "Boundary-aware¬†Transformers¬†for Skin Lesion Segmentation" **MICCAI (2021)**.
  [[paper](https://arxiv.org/abs/2110.03864)]
  [[code](https://github.com/jcwang123/BA-Transformer)]

- **UNETR:** Hatamizadeh, Ali and Tang, Yucheng and Nath, Vishwesh and Yang, Dong and Myronenko, Andriy and Landman, Bennett and Roth, Holger R and Xu, Daguang.<br />
  "UNETR:¬†Transformers¬†for 3D Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://arxiv.org/abs/2103.10504)]
  [[code](https://monai.io/research/unetr)]

- Dobko, Mariia and Kolinko, Danylo-Ivan and Viniavskyi, Ostap and Yelisieiev, Yurii.<br />
  "Combining CNNs With¬†Transformer¬†for Multimodal 3D MRI Brain Tumor Segmentation With Self-Supervised Pretraining" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.07919)]
  [[code](https://github.com/ucuapps/BraTS2021_Challenge)]

- **Bilateral-ViT:** Song, Sifan and Dang, Kang and Yu, Qinji and Wang, Zilong and Coenen, Frans and Su, Jionglong and Ding, Xiaowei.<br />
  "Bilateral-ViT for Robust Fovea Localization" **ISBI (2022)**.
  [[paper](https://arxiv.org/abs/2110.09860)]

- **BiTrans:** Wei, Jianze and Huang, Huaibo and Sun, Muyi and Wang, Yunlong and Ren, Min and He, Ran and Sun, Zhenan.<br />
  "Toward Accurate and Reliable Iris Segmentation Using Uncertainty Learning" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.10334)]

- **AFTer-UNet:** Yan, Xiangyi and Tang, Hao and Sun, Shanlin and Ma, Haoyu and Kong, Deying and Xie, Xiaohui.<br />
  "AFTer-UNet: Axial Fusion¬†Transformer¬†UNet for Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://arxiv.org/abs/2110.10403)]

- **DTNet:** Li, Yunxiang and Li, Jingxiong and Dan, Ruilong and Wang, Shuai and Jin, Kai and Zeng, Guodong and Wang, Jun and Pan, Xiangji and Zhang, Qianni and Zhou, Huiyu and others.<br />
  "Dispensed¬†Transformer¬†Network for Unsupervised Domain Adaptation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2110.14944)]
  [[code](https://github.com/Kent0n-Li/DTNet)]

- **MT-UNet:** Wang, Hongyi and Xie, Shiao and Lin, Lanfen and Iwamoto, Yutaro and Han, Xian-Hua and Chen, Yen-Wei and Tong, Ruofeng.<br />
  "Mixed¬†Transformer¬†U-Net For Medical Image Segmentation" **ICASSP (2022)**.
  [[paper](https://arxiv.org/abs/2111.04734)]
  [[code](https://github.com/Dootmaan/MT-UNet)]

- **VT-UNet:** Peiris, H and Hayat, M and Chen, Z and Egan, G and Harandi, M.<br />
  "A Volumetric¬†Transformer¬†for Accurate 3D Tumor Segmentation" **arXiv (2021)**.
  [[paper](https://arxiv.org/abs/2111.13300)]
  [[code](https://github.com/himashi92/VT-UNet)]

- Tang, Yucheng and Yang, Dong and Li, Wenqi and Roth, Holger R and Landman, Bennett and Xu, Daguang and Nath, Vishwesh and Hatamizadeh, Ali.<br />
  "Self-Supervised Pre-Training of Swin¬†Transformers¬†for 3D Medical Image Analysis" **CVPR (2022)**.
  [[paper](https://arxiv.org/abs/2111.14791)]
  [[code](https://monai.io/research/swin-unetr)]

- **UCTransNet:** Wang, Haonan and Cao, Peng and Wang, Jiaqi and Zaiane, Osmar R.<br />
  "UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer" **AAAI (2022)**.
  [[paper](https://arxiv.org/abs/2109.04335)]
  [[code](https://github.com/McGregorWwww/UCTransNet)]

- **Swin UNETR:** Hatamizadeh, Ali and Nath, Vishwesh and Tang, Yucheng and Yang, Dong and Roth, Holger R and Xu, Daguang.<br />
  "Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images" **International MICCAI Brainlesion Workshop (2021)**.
  [[paper](https://arxiv.org/abs/2201.01266)]
  [[code](https://monai.io/research/swin-unetr)]

- **ViTBIS:** Sagar, Abhinav.<br />
  "ViTBIS: Vision Transformer for Biomedical Image Segmentation" **MICCAI Workshop on Distributed and Collaborative Learning (2021)**.
  [[paper](https://arxiv.org/abs/2201.05920)]

- **TransBTSV2:** Li, Jiangyun and Wang, Wenxuan and Chen, Chen and Zhang, Tianxiang and Zha, Sen and Yu, Hong and Wang, Jing.<br />
  "TransBTSV2: Wider Instead of Deeper Transformer for Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2201.12785)]
  [[code](https://github.com/Wenxuan-1119/TransBTS)]

- **SSFormer:** Wang, Jinfeng and Huang, Qiming and Tang, Feilong and Meng, Jia and Su, Jionglong and Song, Sifan.<br />
  "Stepwise Feature Fusion: Local Guides Global" **MICCAI (2022)**.
  [[paper](https://arxiv.org/abs/2203.03635)]
  [[code](https://github.com/Qiming-Huang/ssformer)]

- **SwinBTS:** Jiang, Yun and Zhang, Yuan and Lin, Xin and Dong, Jinkun and Cheng, Tongtong and Liang, Jing.<br />
  "SwinBTS: A method for 3D multimodal brain tumor¬†segmentation¬†using swin¬†transformer" **Brain sciences (2022)**.
  [[paper](https://www.mdpi.com/2076-3425/12/6/797/pdf)]
  [[code](https://github.com/langwangdezhexue/Swin_BTS)]

- **3D PSwinBTS:** Liang, Junjie and Yang, Cihui and Zeng, Lingguo.<br />
  "3D PSwinBTS: An efficient¬†transformer-based Unet using 3D parallel shifted windows for brain tumor¬†segmentation" **Digital Signal Processing (2022)**.

- **TranSiam:** Li, Xuejian and Ma, Shiqiang and Tang, Jijun and Guo, Fei.<br />
  "TranSiam: Fusing Multimodal Visual Features Using¬†Transformer¬†for¬†Medical¬†Image¬†Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2204.12185)]

- **BTSwin-Unet:** Liang, Junjie and Yang, Cihui and Zhong, Jingting and Ye, Xiaoli.<br />
  "BTSwin-Unet: 3D U-shaped Symmetrical Swin¬†Transformer-based Network for Brain Tumor¬†Segmentation¬†with Self-supervised Pre-trainin" **Neural processing letters (2023)**.

- **TransConver:** Liang, Junjie and Yang, Cihui and Zeng, Mengjie and Wang, Xixi.<br />
  "TransConver: transformer and convolution parallel network for developing automatic brain tumor segmentation in MRI images" **Quantitative Imaging in Medicine and Surgery (2022)**.
  [[paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8923874/)]

- **FCBFormer:** Sanderson, Edward and Matuszewski, Bogdan J.<br />
  "FCN-transformer feature fusion for polyp segmentation" **MIUA (2022)**.
  [[paper](https://link.springer.com/content/pdf/10.1007/978-3-031-12053-4_65.pdf)]
  [[code](https://github.com/CVML-UCLan/FCBFormer)]

- **SwinE-Net:** Park, Kyeong-Beom and Lee, Jae Yeol.<br />
  "SwinE-Net: hybrid deep learning approach to novel polyp segmentation using convolutional neural network and Swin Transformer" **Journal of Computational Design and Engineering (2022)**.
  [[paper](https://academic.oup.com/jcde/article-pdf/9/2/616/43298266/qwac018.pdf10.1007/978-3-031-12053-4_65.pdf)]

- **PCAT-UNet:** Chen, Danny and Yang, Wenzhong and Wang, Liejun and Tan, Sixiang and Lin, Jiangzhaung and Bu, Wenxiu.<br />
  "PCAT-UNet: UNet-like network fused convolution and transformer for retinal vessel segmentation" **PloS one (2022)**.
  [[paper](https://doi.org/10.1371/journal.pone.0262689)]

- **RTN:** Huang, Shiqi and Li, Jianan and Xiao, Yuze and Shen, Ning and Xu, Tingfa.<br />
  "RTNet: Relation transformer network for diabetic retinopathy multi-lesion segmentation" **IEEE Transactions on Medical Imaging (2022)**.
  [[paper](https://arxiv.org/pdf/2201.11037)]

- **MTPA_Unet:** Jiang, Yun and Liang, Jing and Cheng, Tongtong and Lin, Xin and Zhang, Yuan and Dong, Jinkun.<br />
  "MTPA_Unet: Multi-Scale Transformer-Position Attention Retinal Vessel Segmentation Network Joint Transformer and CNN" **Sensors (2022)**.
  [[paper](https://www.mdpi.com/1424-8220/22/12/4592)]

- **UNetFormer:** Hatamizadeh, Ali and Xu, Ziyue and Yang, Dong and Li, Wenqi and Roth, Holger and Xu, Daguang.<br />
  "UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2204.00631)]
  [[code](https://github.com/Project-MONAI/research-contributions)]

- **D-former:** Wu, Yixuan and Liao, Kuanlun and Chen, Jintai and Wang, Jinhong and Chen, Danny Z and Gao, Honghao and Wu, Jian.<br />
  "D-former: A u-shaped dilated transformer for 3d medical image segmentation" **Neural Computing and Applications (2023)**.
  [[paper](https://arxiv.org/abs/2201.00462)]

- **UTNetV2:** Gao, Yunhe and Zhou, Mu and Liu, Di and Metaxas, Dimitris.<br />
  "A Multi-scale Transformer for Medical Image Segmentation: Architectures, Model Efficiency, and Benchmarks" **arXiv (2022)**.
  [[paper](https://www.semanticscholar.org/paper/A-Multi-scale-Transformer-for-Medical-Image-Model-Gao-Zhou/83cefdeb36c001550e3c0e0c45d10d4b80485229)]

- **DSTUNet:** Cai, Zhuotong and Xin, Jingmin and Shi, Peiwen and Wu, Jiayi and Zheng, Nanning.<br />
  "DSTUNet: UNet with Efficient Dense SWIN Transformer Pathway for Medical Image Segmentation" **ISBI (2022)**.

- **CASTformer:** You, Chenyu and Zhao, Ruihan and Liu, Fenglin and Dong, Siyuan and Chinchali, Sandeep and Topcu, Ufuk and Staib, Lawrence and Duncan, James.<br />
  "Class-Aware Generative Adversarial Transformers for Medical Image Segmentation" **NeurIPS (2022)**.
  [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/be99227ef4a4de84bb45d7dc7b53f808-Paper-Conference.pdf)]

- Gao, Yunhe and Zhou, Mu and Liu, Di and Yan, Zhennan and Zhang, Shaoting and Metaxas, Dimitris N.<br />
  "A Data-scalable Transformer for Medical Image Segmentation: Architecture, Model Efficiency, and Benchmark" **arXiv (2022)**.
  [[paper](https://arxiv.org/abs/2203.00131)]

- **mmFormer:** Zhang, Yao and He, Nanjun and Yang, Jiawei and Li, Yuexiang and Wei, Dong and Huang, Yawen and Zhang, Yang and He, Zhiqiang and Zheng, Yefeng.<br />
  "mmFormer: Multimodal Medical Transformer for Incomplete Multimodal Learning of Brain Tumor Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2206.02425)]
  [[code](https://github.com/YaoZhang93/mmFormer)]

- **ColonFormer:** Duc, Nguyen Thanh and Oanh, Nguyen Thi and Thuy, Nguyen Thi and Triet, Tran Minh and Dinh, Viet Sang.<br />
  "ColonFormer: An Efficient Transformer based Method for Colon Polyp Segmentation" **IEEE Access (2022)**.
  [[paper](https://ieeexplore.ieee.org/iel7/6287639/6514899/09845389.pdf)]
  [[code](https://github.com/ducnt9907/ColonFormer)]

- **FCT:** Tragakis, Athanasios and Kaul, Chaitanya and Murray-Smith, Roderick and Husmeier, Dirk.<br />
  "The Fully Convolutional Transformer for Medical Image Segmentation" **WACV (2022)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Tragakis_The_Fully_Convolutional_Transformer_for_Medical_Image_Segmentation_WACV_2023_paper.pdf)]
  [[code](https://github.com/Thanos-DB/)]

- **Patcher:** Ou, Yanglan and Yuan, Ye and Huang, Xiaolei and Wong, Stephen TC and Volpi, John and Wang, James Z and Wong, Kelvin.<br />
  "Patcher: Patch Transformers with Mixture of Experts for Precise Medical Image Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2206.01741)]
  [[code](https://github.com/YanglanOu/patcher.git)]

- **UniMiSS:** Xie, Yutong and Zhang, Jianpeng and Xia, Yong and Wu, Qi.<br />
  "UniMiSS: Universal Medical Self-Supervised Learning via Breaking Dimensionality Barrier" **ECCV (2022)**.
  [[paper](https://arxiv.org/pdf/2112.09356)]
  [[code](https://github.com/YtongXie/UniMiSS-code)]

- **TransResU-Net:** Tomar, Nikhil Kumar and Shergill, Annie and Rieders, Brandon and Bagci, Ulas and Jha, Debesh.<br />
  "TransResU-Net: Transformer based ResU-Net for Real-Time Colonoscopy Polyp Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2206.08985)]
  [[code](https://github.com/nikhilroxtomar/TransResUNet)]

- **LViT:** Li, Zihan and Li, Yunxiang and Li, Qingde and Wang, Puyang and Guo, Dazhou and Lu, Le and Jin, Dakai and Zhang, You and Hong, Qingqi.<br />
  "LViT: Language meets Vision Transformer in Medical Image Segmentation" **IEEE Transactions on Medical Imaging (2023)**.
  [[paper](https://arxiv.org/pdf/2206.14718)]
  [[code](https://github.com/HUANGLIZI/LViT)]

- **HiFormer:** Heidari, Moein and Kazerouni, Amirhossein and Soltany, Milad and Azad, Reza and Aghdam, Ehsan Khodapanah and Cohen-Adad, Julien and Merhof, Dorit.<br />
  "HiFormer: Hierarchical Multi-scale Representations Using Transformers for Medical Image Segmentation" **WACV (2023)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Heidari_HiFormer_Hierarchical_Multi-Scale_Representations_Using_Transformers_for_Medical_Image_Segmentation_WACV_2023_paper.pdf)]
  [[code](https://github.com/amirhossein-kz/HiFormer)]

- **NestedFormer:** Xing, Zhaohu and Yu, Lequan and Wan, Liang and Han, Tong and Zhu, Lei.<br />
  "NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2208.14876)]
  [[code](https://github.com/920232796/NestedFormer)]

- **CR-Swin2-VT:** Peiris, Himashi and Hayat, Munawar and Chen, Zhaolin and Egan, Gary and Harandi, Mehrtash.<br />
  "Hybrid Window Attention Based Transformer Architecture for Brain Tumor Segmentation" **International MICCAI Brainlesion Workshop (2022)**.
  [[paper](https://arxiv.org/pdf/2209.07704)]
  [[code](https://github.com/himashi92/vizviva_fets_2022)]

- Huang, Junjia and Li, Haofeng and Li, Guanbin and Wan, Xiang.<br />
  "Attentive Symmetric Autoencoder for Brain MRI Segmentation" **MICCAI (2022)**.
  [[paper](https://arxiv.org/pdf/2209.08887)]

- **UNesT:** Yu, Xin and Yang, Qi and Zhou, Yinchi and Cai, Leon Y and Gao, Riqiang and Lee, Ho Hin and Li, Thomas and Bao, Shunxing and Xu, Zhoubing and Lasko, Thomas A and others.<br />
  "UNesT: Local Spatial Representation Learning with Hierarchical Transformer for Efficient Medical Segmentation" **Medical Image Analysis (2023)**.
  [[paper](https://arxiv.org/pdf/2209.14378)]
  [[code](https://github.com/MASILab/UNesT)]

- **FINE:** Themyr, Loic and Rambour, Cl{\'e}ment and Thome, Nicolas and Collins, Toby and Hostettler, Alexandre.<br />
  "Memory transformers for full context and high-resolution 3D Medical Segmentation" **International Workshop on Machine Learning in Medical Imaging (2022)**.
  [[paper](https://arxiv.org/pdf/2210.05313)]

- **CTS:** Gong, Zhendi and French, Andrew P and Qiu, Guoping and Chen, Xin.<br />
  "ConvTransSeg: A Multi-resolution Convolution-Transformer Network for Medical Image Segmentation" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2210.07072)]

- **CS-Unet:** Liu, Qianying and Kaul, Chaitanya and Wang, Jun and Anagnostopoulos, Christos and Murray-Smith, Roderick and Deligianni, Fani.<br />
  "Optimizing Vision Transformers for Medical Image Segmentation" **ICASSP (2023)**.
  [[paper](https://arxiv.org/pdf/2210.08066)]
  [[code](https://github.com/kathyliu579/CS-Unet)]

- **MEW-UNET:** Ruan, Jiacheng and Xie, Mingye and Xiang, Suncheng and Liu, Ting and Fu, Yuzhuo.<br />
  "MEW-UNET: MULTI-AXIS REPRESENTATION LEARNING IN FREQUENCY DOMAIN FOR MEDICAL IMAGE SEGMENTATION" **arXiv (2022)**.
  [[paper](https://arxiv.org/pdf/2210.14007)]
  [[code](https://github.com/JCruan519/MEW-UNet)]

- Li, Yijiang and Cai, Wentian and Gao, Ying and Li, Chengming and Hu, Xiping.<br />
  "More than Encoder: Introducing Transformer Decoder to Upsample" **IEEE BIBM (2022)**.
  [[paper](https://arxiv.org/pdf/2106.10637)]

- **UNETR++:** Shaker, Abdelrahman M and Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Yang, Ming-Hsuan and Khan, Fahad Shahbaz.<br />
  "UNETR++: Delving into Efficient and Accurate 3D Medical Image Segmentation" **IEEE Transactions on Medical Imaging (2024)**.
  [[paper](https://ieeexplore.ieee.org/iel7/42/4359023/10526382.pdf)]
  [[code](https://tinyurl.com/2p87x5xn)]
  
- **DAE-Former:** Azad, Reza and Arimond, Ren{\'e} and Aghdam, Ehsan Khodapanah and Kazerouni, Amirhossein and Merhof, Dorit.<br />
  "DAE-Former: Dual Attention-guided Efficient Transformer for Medical Image Segmentation" **International Workshop on PRedictive Intelligence In MEdicine (2023)**.
  [[paper](https://arxiv.org/pdf/2212.13504)]
  [[code](https://github.com/mindflow-institue/DAEFormer)]

- **TransCeption:** Azad, Reza and Jia, Yiwei and Aghdam, Ehsan Khodapanah and Cohen-Adad, Julien and Merhof, Dorit.<br />
  "Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2301.10847)]
  [[code](https://github.com/mindflow-institue/TransCeption)]

- **MAXVIT-UNET:** Khan, Abdul Rehman and Khan, Asifullah.<br />
  "MAXVIT-UNET: MULTI-AXIS ATTENTION FOR MEDICAL IMAGE SEGMENTATION" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2305.08396)]
  [[code](https://github.com/PRLAB21/MaxViT-UNet)]

- **MIST:** Rahman, Md Motiur and Shokouhmand, Shiva and Bhatt, Smriti and Faezipour, Miad.<br />
  "MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder" **WACV (2024)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2024/papers/Rahman_MIST_Medical_Image_Segmentation_Transformer_With_Convolutional_Attention_Mixing_CAM_WACV_2024_paper.pdf)]
  [[code](https://github.com/Rahman-Motiur/MIST)]

- **MS-Twins:** Xu, Jing.<br />
  "MS-TwinsÔºöMulti-Scale Deep Self-Attention Networks for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2312.07128)]

- **Cascaded MERIT:** Rahman, Md Mostafijur and Marculescu, Radu.<br />
  "Multi-scale hierarchical vision transformer with cascaded attention decoding for medical image segmentation" **MIDL (2024)**.
  [[paper](https://proceedings.mlr.press/v227/rahman24a/rahman24a.pdf)]
  [[code](https://github.com/SLDGroup/MERIT)]

- Rahman, Md Mostafijur and Marculescu, Radu.<br />
  "Medical image segmentation via cascaded attention decoding" **WACV (2023)**.
  [[paper](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.pdf)]
  [[code](https://github.com/SLDGroup/MERIT)]

- **D-TrAttUnet:** Bougourzi, Fares and Dornaika, Fadi and Distante, Cosimo and Taleb-Ahmed, Abdelmalik.<br />
  "D-TrAttUnet: Toward Hybrid CNN-Transformer Architecture for Generic and Subtle Segmentation in Medical Images" **Computers in Biology and Medicine (2024)**.
  [[paper](https://www.sciencedirect.com/science/article/pii/S0010482524006759)]
  [[code](https://github.com/faresbougourzi/D-TrAttUnet)]

- **PAGTransYnet:** Bougourzi, Fares and Dornaika, Fadi and Taleb-Ahmed, Abdelmalik and Hoang, Vinh Truong.<br />
  "Rethinking Attention Gated with Hybrid Dual Pyramid Transformer-CNN for Generalized Segmentation in Medical Imaging" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.18199)]
  [[code](https://github.com/faresbougourzi/PAGTransYnet)]

- **PAG-TransYnet:** Bougourzi, Fares and Dornaika, Fadi and Taleb-Ahmed, Abdelmalik and Hoang, Vinh Truong.<br />
  "Rethinking Attention Gated with Hybrid Dual Pyramid Transformer-CNN for Generalized Segmentation in Medical Imaging" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.18199)]
  [[code](https://github.com/faresbougourzi/PAGTransYnet)]

- **SegFormer3D:** Perera, Shehan and Navard, Pouyan and Yilmaz, Alper.<br />
  "SegFormer3D: an Efficient Transformer for 3D Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.10156)]
  [[code](https://github.com/OSUPCVLab/SegFormer3D.git)]

- **3D-EffiViTCaps:** Gan, Dongwei and Chang, Ming and Chen, Juan.<br />
  "3D-EffiViTCaps: 3D Efficient Vision Transformer with Capsule for Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2403.16350)]
  [[code](https://github.com/HidNeuron/3D-EffiViTCaps)]

- **BEFUnet:** Manzari, Omid Nejati and Kaleybar, Javad Mirzapour and Saadat, Hooman and Maleki, Shahin.<br />
  "BEFUnet: A Hybrid CNN-Transformer Architecture for Precise Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2402.08793)]
  [[code](https://github.com/Omid-Nejati/BEFUnet)]

- **ScribFormer:** Li, Zihan and Zheng, Yuan and Shan, Dandan and Yang, Shuzhou and Li, Qingde and Wang, Beizhan and Zhang, Yuanting and Hong, Qingqi and Shen, Dinggang.<br />
  "ScribFormer: Transformer Makes CNN Work Better for Scribble-based Medical Image Segmentation" **IEEE Transactions on Medical Imaging (2024)**.
  [[paper](https://arxiv.org/html/2402.02029v1)]
  [[code](https://github.com/HUANGLIZI/ScribFormer)]

- **MOSformer:** Huang, De-Xing and Zhou, Xiao-Hu and Xie, Xiao-Liang and Liu, Shi-Qi and Feng, Zhen-Qiu and Gui, Mei-Jiang and Li, Hao and Xiang, Tian-Yu and Liu, Xiu-Ling and Hou, Zeng-Guang.<br />
  "MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2401.11856)]

- **BRAU-Net++:** Lan, Libin and Cai, Pengzhou and Jiang, Lu and Liu, Xiaojuan and Li, Yongmei and Zhang, Yudong.<br />
  "BRAU-Net++: U-Shaped Hybrid CNN-Transformer Network for Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2401.00722)]
  [[code](https://github.com/Caipengzhou/BRAU-Netplusplus)]

- **MobileUtr:** Tang, Fenghe and Nian, Bingkun and Ding, Jianrui and Quan, Quan and Yang, Jie and Liu, Wei and Zhou, S Kevin.<br />
  "MobileUtr: Revisiting the relationship between light-weight CNN and Transformer for efficient medical image segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/abs/2312.01740)]
  [[code](https://github.com/FengheTan9/MobileUtr)]

- **DA-TransUNet:** Sun, Guanqun and Pan, Yizhi and Kong, Weikun and Xu, Zichang and Ma, Jianhua and Racharak, Teeradaj and Nguyen, Le-Minh.<br />
  "DA-TransUNet: Integrating Spatial and Channel Dual Attention with Transformer U-Net for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.12570)]
  [[code](https://github.com/SUN-1024/DA-TransUnet)]

- **SeUNet-Trans:** Pham, Tan-Hanh and Li, Xianqi and Nguyen, Kim-Doang.<br />
  "SeUNet-Trans: A Simple yet Effective UNet-Transformer Model for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.09998)]

- **3D-TransUNet:** Chen, Jieneng and Mei, Jieru and Li, Xianhang and Lu, Yongyi and Yu, Qihang and Wei, Qingyue and Luo, Xiangde and Xie, Yutong and Adeli, Ehsan and Wang, Yan and others.<br />
  "3D TransUNet: Advancing Medical Image Segmentation through Vision Transformers" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2310.07781)]
  [[code](https://github.com/Beckschen/3D-TransUNet)]

- **C-ViT:** Bastico, Matteo and Ryckelynck, David and Cort{\'e}, Laurent and Tillier, Yannick and Decenci{\`e}re, Etienne.<br />
  "A Simple and Robust Framework for Cross-Modality Medical Image Segmentation applied to Vision Transformers" **ICCV (2023)**.
  [[paper](https://openaccess.thecvf.com/content/ICCV2023W/LXCV/papers/Bastico_A_Simple_and_Robust_Framework_for_Cross-Modality_Medical_Image_Segmentation_ICCVW_2023_paper.pdf)]
  [[code](https://github.com/matteo-bastico/MI-Seg)]

- **ConvFormer:** Lin, Xian and Yan, Zengqiang and Deng, Xianbo and Zheng, Chuansheng and Yu, Li.<br />
  "ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2309.05674)]
  [[code](https://github.com/xianlin7/ConvFormer)]

- **SwinMM:** Wang, Yiqing and Li, Zihan and Mei, Jieru and Wei, Zihao and Liu, Li and Wang, Chen and Sang, Shengtian and Yuille, Alan L and Xie, Cihang and Zhou, Yuyin.<br />
  "SwinMM: Masked Multi-view with Swin Transformers for 3D Medical Image Segmentation" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2307.12591)]
  [[code](https://github.com/UCSC-VLAA/SwinMM/)]

- **MDViT:** Du, Siyi and Bayasi, Nourhan and Hamarneh, Ghassan and Garbi, Rafeef.<br />
  "MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2307.02100)]
  [[code](https://github.com/siyi-wind/MDViT)]

- **TEC-Net:** Lei, Tao and Sun, Rui and Wan, Yong and Xia, Yong and Du, Xiaogang and Nandi, Asoke K.<br />
  "TEC-Net: Vision Transformer Embrace Convolutional Neural Networks for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2306.04086)]
  [[code](https://github.com/SR0920/TECNet)]

- **CiT-Net:** Lei, Tao and Sun, Rui and Wang, Xuan and Wang, Yingbo and He, Xi and Nandi, Asoke.<br />
  "CiT-Net: Convolutional Neural Networks Hand in Hand with Vision Transformers for Medical Image Segmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2306.03373)]
  [[code](https://github.com/SR0920/CiT-Net)]

- **TAB:** Liao, Zehui and Hu, Shishuai and Xie, Yutong and Xia, Yong.<br />
  "Transformer-based Annotation Bias-aware Medical Image Segmentation" **MICCAI (2023)**.
  [[paper](https://arxiv.org/pdf/2306.01340)]

- Saeed, Numan and Ridzuan, Muhammad and Majzoub, Roba Al and Yaqub, Mohammad.<br />
  "Prompt-Based Tuning of Transformer Models for Multi-Center Medical Image Segmentation of Head and Neck Cancer" **Bioengineering (2023)**.
  [[paper](https://arxiv.org/abs/2305.18948)]

- **STM-UNet:** Shi, Lei and Gao, Tianyu and Zhang, Zheng and Zhang, Junxing.<br />
  "STM-UNet: An Efficient U-shaped Architecture Based on Swin Transformer and Multi-scale MLP for Medical Image Segmentation" **IEEE GLOBECOM (2023)**.
  [[paper](https://arxiv.org/pdf/2304.12615)]

- **Dilated-UNet:** Saadati, Davoud and Manzari, Omid Nejati and Mirzakuchaki, Sattar.<br />
  "Dilated-UNet: A Fast and Accurate Medical Image Segmentation Approach using a Dilated Transformer and U-Net Architecture" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2304.11450)]
  [[code](https://github.com/Omid-Nejati/Dilated_Unet)]

- **HST-MRF:** Huang, Xiaofei and Gong, Hongfang and Zhang, Jin.<br />
  "HST-MRF: Heterogeneous Swin Transformer with Multi-Receptive Field for Medical Image Segmentation" **IEEE Journal of Biomedical and Health Informatics (2024)**.
  [[paper](https://arxiv.org/pdf/2304.04614)]

- **U-Netmer:** He, Sheng and Bao, Rina and Grant, P Ellen and Ou, Yangming.<br />
  "U-Netmer:U-NetmeetsTransformer formedical imagesegmentation" **arXiv (2023)**.
  [[paper](https://arxiv.org/pdf/2304.01401)]

- Yuan, Mingze and Xia, Yingda and Dong, Hexin and Chen, Zifan and Yao, Jiawen and Qiu, Mingyan and Yan, Ke and Yin, Xiaoli and Shi, Yu and Chen, Xin and others.<br />
  "Devil is in the Queries: Advancing Mask Transformers for Real-world Medical Image Segmentation and Out-of-Distribution Localization" **CVPR (2023)**.
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Yuan_Devil_Is_in_the_Queries_Advancing_Mask_Transformers_for_Real-World_CVPR_2023_paper.pdf)]


### Mamba in medical Segmentation
- **Mamba:** Gu, Albert and Dao, Tri.<br />
  "Mamba: Linear-Time Sequence Modeling with Selective State Spaces" **arXiv (2023)**.
  [[paper](https://arxiv.org/abs/2312.00752)] 

- **Vim:** Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang.<br />
  "Vision mamba: Efficient visual representation learning with bidirectional state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.09417)] 

- **Vmamba:** Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan.<br />
  "Vmamba: Visual state space model" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.10166)]
  [[code](https://github.com/MzeroMiko/VMamba)]

- **Segmamba:** Xing, Zhaohu and Ye, Tian and Yang, Yijun and Liu, Guang and Zhu, Lei.<br />
  "Segmamba: Long-range sequential modeling mamba for 3d medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.13560)]
  [[code]()]

- **U-mamba:** Ma, Jun and Li, Feifei and Wang, Bo.<br />
  "U-mamba: Enhancing long-range dependency for biomedical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2401.04722)]
  [[code](https://wanglab.ai/u-mamba.html)]

- **H-vmunet:** Wu, Renkai and Liu, Yinghao and Liang, Pengchen and Chang, Qing.<br />
  "H-vmunet: High-order vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.13642)]
  [[code](https://github.com/wurenkai/H-vmunet)]

- **LightM-UNet:** Liao, Weibin and Zhu, Yinghao and Wang, Xinyuan and Pan, Cehngwei and Wang, Yasha and Ma, Liantao.<br />
  "Lightm-unet: Mamba assists in lightweight unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.05246)]
  [[code](https://github.com/MrBlankness/LightM-UNet)]

- **Swin-UMamba:** Liu, Jiarun and Yang, Hao and Zhou, Hong-Yu and Xi, Yan and Yu, Lequan and Yu, Yizhou and Liang, Yong and Shi, Guangming and Zhang, Shaoting and Zheng, Hairong and others.<br />
  "Swin-umamba: Mamba-based unet with imagenet-based pretraining" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.03302)]
  [[code](https://github.com/JiarunLiu/Swin-UMamba)]

- **VM-UNet:** Ruan, Jiacheng and Xiang, Suncheng.<br />
  "Vm-unet: Vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.02491)]
  [[code](https://github.com/JCruan519/VM-UNet)]

- **VM-UNET-V2:** Zhang, Mingya and Yu, Yue and Gu, Limei and Lin, Tingsheng and Tao, Xianping.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.09157)]
  [[code](https://github.com/nobodyplayer1/VM-UNetV2)]

- **LMa-UNet:** Wang, Jinhong and Chen, Jintai and Chen, Danny and Wu, Jian.<br />
  "Large window-based mamba unet for medical image segmentation: Beyond convolution and self-attention" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.07332)]
  [[code](https://github.com/wjh892521292/LMa-UNet)]

- **Mamba-UNet:** Wang, Ziyang and Zheng, Jian-Qing and Zhang, Yichi and Cui, Ge and Li, Lei.<br />
  "Vm-unet-v2 rethinking vision mamba unet for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.05079)]
  [[code](https://github.com/ziyangwang007/Mamba-UNet)]

- **TM-UNet:** Tang, Hao and Cheng, Lianglun and Huang, Guoheng and Tan, Zhengguang and Lu, Junhao and Wu, Kaihong.<br />
  "Rotate to scan: Unet-like mamba with triplet ssm module for medical image segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2403.17701)]

- **P-Mamba:** Ye, Zi and Chen, Tianxiang.<br />
  "P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2402.08506)]

- **Mamba‚ÄëHUNet:** Sanjid, Kazi Shahriar and Hossain, Md Tanzim and Junayed, Md Shakib Shahariar and Uddin, Dr Mohammad Monir.<br />
  "Integrating mamba sequence model and hierarchical upsampling network for accurate semantic segmentation of multiple sclerosis legion" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2403.17432)]

- **ViM-UNet:** Archit, Anwai and Pape, Constantin.<br />
  "ViM-UNet: Vision Mamba for Biomedical Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2404.07705)]
  [[code](https://github.com/constantinpape/torch-em/blob/main/vimunet.md)]

- **UltraLight VM‚ÄëUnet:** Wu, Renkai and Liu, Yinghao and Liang, Pengchen and Chang, Qing.<br />
  "Ultralight vm-unet: Parallel vision mamba significantly reduces parameters for skin lesion segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2403.20035)]
  [[code](https://github.com/wurenkai/UltraLight-VM-UNet)]

  - **Prompt-Mamba:** Xie, Jianhao and Liao, Ruofan and Zhang, Ziang and Yi, Sida and Zhu, Yuesheng and Luo, Guibo.<br />
  "Promamba: Prompt-mamba for polyp segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/pdf/2403.13660)]

- **T-mamba:** Hao, Jing and He, Lei and Hung, Kuo Feng.<br />
  "T-mamba: Frequency-enhanced gated long-range dependency for tooth 3d cbct segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2404.01065)]
  [[code](https://github.com/isbrycee/T-Mamba)]

  - **HC-Mamba:** Xu, Jiashu.<br />
  "HC-Mamba: Vision MAMBA with Hybrid Convolutional Techniques for Medical Image Segmentation" **arXiv (2024)**.
  [[paper](https://arxiv.org/abs/2405.05007)]
  
  
  
